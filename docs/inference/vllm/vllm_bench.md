# vLLM æ€§èƒ½åŸºå‡†æµ‹è¯•æŒ‡å—ï¼šå…¨é¢è¯„ä¼°å¤§æ¨¡å‹æ¨ç†æ€§èƒ½

## å¼•è¨€

åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Models, LLMsï¼‰çš„ç”Ÿäº§éƒ¨ç½²ä¸­ï¼Œæ¨ç†æ€§èƒ½æ˜¯å†³å®šç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿæˆæœ¬çš„å…³é”®å› ç´ ã€‚[vLLM](https://github.com/vllm-project/vllm) ä½œä¸ºä¸šç•Œé¢†å…ˆçš„é«˜æ•ˆæ¨ç†å¼•æ“ï¼Œä¸ä»…æä¾›äº†å¼ºå¤§çš„åŠŸèƒ½æ”¯æŒï¼ˆå¦‚ PagedAttentionã€LoRAã€å¤šæ¨¡æ€ç­‰ï¼‰ï¼Œè¿˜å†…ç½®äº†ä¸€å¥—**å…¨é¢ä¸”çµæ´»çš„åŸºå‡†æµ‹è¯•å·¥å…·é›†**ï¼Œå¸®åŠ©å¼€å‘è€…é‡åŒ–è¯„ä¼°æ¨¡å‹åœ¨ä¸åŒåœºæ™¯ä¸‹çš„è¡¨ç°ã€‚

æœ¬æ–‡å°†ç³»ç»Ÿä»‹ç» vLLM çš„åŸºå‡†æµ‹è¯•ä½“ç³»ï¼Œæ¶µç›–å…¶ CLI å·¥å…·ã€æ”¯æŒçš„æ•°æ®é›†ã€å…¸å‹ä½¿ç”¨åœºæ™¯ä»¥åŠé«˜çº§åŠŸèƒ½ï¼ŒåŠ©æ‚¨ç²¾å‡†è¡¡é‡æ¨ç†æ€§èƒ½ã€‚

## ä¸€ã€vLLM åŸºå‡†æµ‹è¯•ä½“ç³»æ¦‚è§ˆ

vLLM çš„åŸºå‡†æµ‹è¯•ä¸»è¦åˆ†ä¸ºä¸‰å¤§ç±»ï¼š

1. **Benchmark CLI å·¥å…·**
   æä¾›å‘½ä»¤è¡Œæ¥å£ï¼ˆ`vllm bench`ï¼‰ï¼Œç”¨äºäº¤äº’å¼æˆ–è„šæœ¬åŒ–åœ°æ‰§è¡Œåœ¨çº¿/ç¦»çº¿æ€§èƒ½æµ‹è¯•ã€‚
2. **è‡ªåŠ¨åŒ– CI æ€§èƒ½åŸºå‡†**
   åœ¨æ¯æ¬¡ä»£ç æäº¤æ—¶è‡ªåŠ¨è¿è¡Œï¼Œç¡®ä¿æ–°åŠŸèƒ½ä¸ä¼šå¼•å…¥æ€§èƒ½é€€åŒ–ã€‚
3. **æ¨ªå‘å¯¹æ¯”åŸºå‡†ï¼ˆNightly Benchmarksï¼‰**
   å®šæœŸå°† vLLM ä¸ç«å“ï¼ˆå¦‚ TGIã€TensorRT-LLMã€LMDeployï¼‰è¿›è¡Œæ¨ªå‘å¯¹æ¯”ï¼Œç»“æœå…¬å¼€å‘å¸ƒäº [vLLM æ€§èƒ½ä»ªè¡¨ç›˜](https://docs.vllm.ai/en/stable/contributing/benchmarks.html#nightly-benchmarks)ã€‚

æœ¬æ–‡é‡ç‚¹èšç„¦äºç¬¬ä¸€ç±»â€”â€”å¼€å‘è€…å¯ç›´æ¥ä½¿ç”¨çš„ **Benchmark CLI**ã€‚

### åŸºå‡†æµ‹è¯•å‘½ä»¤è¡Œæ¥å£ (Benchmark CLI)

æ‰€æœ‰åŸºå‡†æµ‹è¯•çš„å…¥å£ç‚¹éƒ½æ˜¯ç»Ÿä¸€çš„å‘½ä»¤è¡Œå·¥å…·ï¼Œé€šå¸¸é€šè¿‡ `vllm bench` å‘½ä»¤è°ƒç”¨ã€‚

è¿™ä¸€å‘½ä»¤æ˜¯æ‚¨æ‰§è¡Œæ‰€æœ‰æ€§èƒ½è¯„ä¼°çš„èµ·ç‚¹ï¼Œä¸åŒçš„å­å‘½ä»¤å’Œå‚æ•°å°†å¼•å¯¼æ‚¨è¿›å…¥ç‰¹å®šçš„æµ‹è¯•åœºæ™¯ã€‚ä¾‹å¦‚ï¼š

- è¿è¡Œå»¶è¿Ÿæµ‹è¯•ï¼š`vllm bench latency [...]`
- è¿è¡ŒæœåŠ¡ååé‡æµ‹è¯•ï¼š`vllm bench serve [...]`
- è¿è¡Œç¦»çº¿ååé‡æµ‹è¯•ï¼š`vllm bench throughput [...]`


## äºŒã€æ ¸å¿ƒæ€§èƒ½åŸºå‡†æµ‹è¯•å¥—ä»¶å’Œæµ‹è¯•åœºæ™¯

vLLMçš„æ€§èƒ½è¯„ä¼°è¢«ç²¾ç»†åœ°åˆ’åˆ†ä¸ºä¸¤å¤§æ ¸å¿ƒç±»åˆ«ï¼Œåˆ†åˆ«å¯¹åº”åœ¨çº¿æœåŠ¡å’Œç¦»çº¿æ‰¹å¤„ç†åœºæ™¯ï¼Œè¿™æ˜¯ä»»ä½•LLMæ¨ç†å¼•æ“éƒ½å¿…é¡»ä¼˜åŒ–çš„å…³é”®æŒ‡æ ‡ã€‚

### 1. åœ¨çº¿åŸºå‡†æµ‹è¯• (Online Benchmark)

**æ ¸å¿ƒç›®æ ‡ï¼š** æ¨¡æ‹ŸçœŸå®çš„ç”¨æˆ·è¯·æ±‚æµé‡ï¼Œè¯„ä¼°ç³»ç»Ÿçš„**å»¶è¿Ÿ**å’Œ**æœåŠ¡èƒ½åŠ›**ï¼Œç›´æ¥å…³ç³»åˆ°ç»ˆç«¯ç”¨æˆ·ä½“éªŒå’ŒSLAï¼ˆæœåŠ¡ç­‰çº§åè®®ï¼‰ã€‚

- **å»¶è¿Ÿæµ‹è¯• (Latency)**ï¼šè¡¡é‡è¯·æ±‚çš„ç«¯åˆ°ç«¯æ—¶é—´ï¼ŒåŒ…æ‹¬é¦–ä¸ªTokençš„å»¶è¿Ÿï¼ˆTime To First Token, TTFTï¼‰å’Œåç»­Tokençš„å¹³å‡ç”Ÿæˆå»¶è¿Ÿï¼ˆTime Per Output Token, TPOTï¼‰ã€‚è¿™æ˜¯è¯„ä¼°è°ƒåº¦å™¨å’Œ KV Cache è®¿é—®æ•ˆç‡çš„å…³é”®ã€‚
- **æœåŠ¡æ€§èƒ½æµ‹è¯• (Serve)**ï¼šåœ¨å¤šå¹¶å‘ã€é«˜è´Ÿè½½ç¯å¢ƒä¸‹è¿è¡Œï¼Œè¯„ä¼°ç³»ç»Ÿçš„æœ€å¤§å¹¶å‘è¯·æ±‚å¤„ç†èƒ½åŠ›å’Œåœ¨ç‰¹å®šå»¶è¿Ÿé™åˆ¶ä¸‹çš„ç¨³å®šååé‡ã€‚

### 2. ç¦»çº¿ååé‡åŸºå‡†æµ‹è¯• (Offline Throughput Benchmark)

**æ ¸å¿ƒç›®æ ‡ï¼š** è¯„ä¼°ç³»ç»Ÿåœ¨èµ„æºé¥±å’ŒçŠ¶æ€ä¸‹çš„**æœ€å¤§å¤„ç†èƒ½åŠ›**ï¼Œé€šå¸¸ä»¥æ¯ç§’ç”Ÿæˆçš„Tokenæ•°ï¼ˆTokens/sï¼‰æ¥è¡¡é‡ã€‚

æ­¤æµ‹è¯•é€‚ç”¨äºè¯„ä¼°åº•å±‚CUDA/Tritonå†…æ ¸ã€å¼ é‡å¹¶è¡Œï¼ˆTensor Parallelismï¼‰å’ŒKV Cacheç®¡ç†ç­‰ç»„ä»¶çš„çº¯ç²¹è®¡ç®—æ•ˆç‡ã€‚å®ƒå…³æ³¨çš„æ˜¯åœ¨ä¸è€ƒè™‘å®æ—¶å»¶è¿Ÿé™åˆ¶ä¸‹çš„æé™æ€§èƒ½ã€‚

### 3. ç‰¹æ€§ä¸åœºæ™¯ç‰¹å®šçš„åŸºå‡†æµ‹è¯•

vLLMçš„åŸºå‡†æµ‹è¯•å¥—ä»¶è¿˜åŒ…å«ä¸€ç³»åˆ—é’ˆå¯¹ç‰¹å®šé«˜çº§ç‰¹æ€§å’Œå¤æ‚å·¥ä½œè´Ÿè½½è®¾è®¡çš„æµ‹è¯•ï¼Œä»¥ç¡®ä¿å…³é”®åˆ›æ–°ä¸ä¼šå¼•å…¥æ€§èƒ½é€€åŒ–ã€‚

| åŸºå‡†æµ‹è¯•åç§°       | æ ¸å¿ƒè¯„ä¼°ç›®æ ‡                                                       | å¯¹åº”åœºæ™¯                  | å…³é”®æŠ€æœ¯æ·±åº¦                                                     |
| ------------------ | ------------------------------------------------------------------ | ------------------------- | ---------------------------------------------------------------- |
| ç»“æ„åŒ–è¾“å‡ºåŸºå‡†æµ‹è¯• | è¯„ä¼°åœ¨ç‰¹å®šæ ¼å¼ï¼ˆå¦‚JSON Schemaã€Regexï¼‰çº¦æŸä¸‹ç”Ÿæˆå†…å®¹çš„æ•ˆç‡å’Œæ­£ç¡®æ€§ | RAGã€å‡½æ•°è°ƒç”¨ã€Agent ä»»åŠ¡ | çº¦æŸè§£ç ã€Logits Processor çš„æ€§èƒ½å¼€é”€                            |
| é•¿æ–‡æ¡£é—®ç­”åŸºå‡†æµ‹è¯• | è¯„ä¼°å¤„ç†è¶…é•¿ä¸Šä¸‹æ–‡çª—å£æ—¶çš„æ€§èƒ½å’Œå†…å­˜ç®¡ç†æ•ˆç‡                       | é•¿ä¸Šä¸‹æ–‡æ¨¡å‹ã€æ–‡æ¡£å¤„ç†    | é•¿ä¸Šä¸‹æ–‡ KV Cache çš„å†…å­˜å¼€é”€ã€Paged Attention åœ¨å¤§è§„æ¨¡å—ä¸Šçš„æ•ˆç‡ |
| å‰ç¼€ç¼“å­˜åŸºå‡†æµ‹è¯•   | è¯„ä¼°**è‡ªåŠ¨å‰ç¼€ç¼“å­˜ (Automatic Prefix Caching)** æœºåˆ¶çš„å®é™…åŠ é€Ÿæ•ˆæœ | å¤šç”¨æˆ·æˆ–é‡å¤æç¤ºè¯åœºæ™¯    | KV Cache çš„å‘½ä¸­ç‡ã€Prefill é˜¶æ®µçš„è®¡ç®—ä¼˜åŒ–                        |
| è¯·æ±‚ä¼˜å…ˆçº§åŸºå‡†æµ‹è¯• | è¯„ä¼°è°ƒåº¦å™¨å¤„ç†å…·æœ‰ä¸åŒä¼˜å…ˆçº§çš„å¹¶å‘è¯·æ±‚æ—¶çš„å“åº”é€Ÿåº¦å’ŒSLAä¿éšœèƒ½åŠ›    | å¤šç§Ÿæˆ·ã€SLA ä¿è¯åœºæ™¯      | è°ƒåº¦å™¨é€»è¾‘ã€Request Prioritization æœºåˆ¶çš„æœ‰æ•ˆæ€§                  |
| å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•     | è¯„ä¼°é›†æˆå›¾åƒã€éŸ³é¢‘ç­‰è¾“å…¥åï¼Œæ¨¡å‹çš„æ¨ç†æ€§èƒ½å’Œå»¶è¿Ÿ                   | å¤šæ¨¡æ€è¾“å…¥å¤„ç†            | å¤šæ¨¡æ€è¾“å…¥é¢„å¤„ç†ã€æ•°æ®å¹¶è¡Œä¸è®¡ç®—èµ„æºçš„åè°ƒ                       |
| Embedding åŸºå‡†æµ‹è¯• | è¯„ä¼° vLLM åœ¨æ‰§è¡Œå‘é‡åµŒå…¥ä»»åŠ¡æ—¶çš„ååé‡å’Œå»¶è¿Ÿ                       | æ£€ç´¢å¢å¼ºã€å‘é‡æ•°æ®åº“é›†æˆ  | Pooling Model çš„æ•ˆç‡ã€æ‰¹å¤„ç†èƒ½åŠ›                                 |
| Reranker åŸºå‡†æµ‹è¯•  | è¯„ä¼°é‡æ’åºæ¨¡å‹ï¼ˆReranker Modelï¼‰çš„æ€§èƒ½                             | æ£€ç´¢å¢å¼ºã€å‘é‡æ•°æ®åº“é›†æˆ  | ä¸“ç”¨äºè¯„ä¼°éç”Ÿæˆç±»ï¼ˆEncoder-onlyï¼‰æ¨¡å‹çš„æ¨ç†èƒ½åŠ›                 |

## ä¸‰ã€æ”¯æŒçš„æ•°æ®é›†

vLLM æ”¯æŒå¤šç§çœŸå®ä¸–ç•Œå’Œåˆæˆæ•°æ®é›†ï¼Œè¦†ç›–æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘ç­‰å¤šç§æ¨¡æ€ï¼š

| æ•°æ®é›†åç§°                | åœ¨çº¿æµ‹è¯• | ç¦»çº¿æµ‹è¯• | æ•°æ®æ¥æº                 |
| ------------------------- | -------- | -------- | ------------------------ |
| ShareGPT                  | âœ…        | âœ…        | Hugging Face             |
| ShareGPT4V (å›¾åƒ)         | âœ…        | âœ…        | Hugging Face + COCO å›¾åƒ |
| ShareGPT4Video (è§†é¢‘)     | âœ…        | âœ…        | Hugging Face             |
| BurstGPT                  | âœ…        | âœ…        | GitHub Release           |
| Random                    | âœ…        | âœ…        | synthetic                |
| Prefix Repetition         | âœ…        | âœ…        | synthetic                |
| HuggingFace-VisionArena   | âœ…        | âœ…        | Hugging Face             |
| HuggingFace-MMVU          | âœ…        | âœ…        | Hugging Face             |
| HuggingFace-InstructCoder | âœ…        | âœ…        | Hugging Face             |
| HuggingFace-AIMO          | âœ…        | âœ…        | Hugging Face             |
| MT-Bench / Blazedit       | âœ…        | âœ…        | Hugging Face             |
| Spec-Bench                | âœ…        | âœ…        | GitHub                   |
| è‡ªå®šä¹‰æ•°æ®é›†              | âœ…        | âœ…        | æœ¬åœ° `.jsonl` æ–‡ä»¶       |

> **æç¤º**ï¼šå¯¹äº Hugging Face æ•°æ®é›†ï¼Œè¯·ä½¿ç”¨ `--dataset-name hf` å¹¶æŒ‡å®š `--hf-name`ï¼›å¯¹äºæœ¬åœ°æ–‡ä»¶ï¼Œä½¿ç”¨ `--dataset-name custom`ã€‚

ä¸ºäº†ç¡®ä¿æµ‹è¯•çš„å…¬å¹³æ€§å’Œä»£è¡¨æ€§ï¼ŒvLLM ä½¿ç”¨äº†ä¸€ç³»åˆ—æ ‡å‡†åŒ–çš„æ•°æ®é›†å’Œæç¤ºè¯æ¨¡æ¿ï¼Œè´¡çŒ®è€…åº”å…³æ³¨ï¼š

1. **æ•°æ®é›†é€‰æ‹©:** äº†è§£ä¸åŒåŸºå‡†æµ‹è¯•ä½¿ç”¨çš„æ•°æ®é›†ï¼Œç¡®ä¿è‡ªå·±çš„æ€§èƒ½æ”¹è¿›åœ¨ç›¸å…³æ•°æ®é›†ä¸Šæœ‰æ•ˆã€‚
2. **ç¤ºä¾‹å‚è€ƒ:** å®˜æ–¹æ–‡æ¡£æä¾›äº†è¿è¡Œå„ä¸ªåŸºå‡†æµ‹è¯•çš„å®Œæ•´ç¤ºä¾‹å‘½ä»¤ï¼Œæ˜¯è¿è¡Œæµ‹è¯•çš„é¦–é€‰å‚è€ƒã€‚



## å››ã€æ ¸å¿ƒåŸºå‡†æµ‹è¯•åœºæ™¯ä¸ç¤ºä¾‹

### 1. åœ¨çº¿æœåŠ¡åŸºå‡†æµ‹è¯•ï¼ˆOnline Serving Benchmarkï¼‰

æ¨¡æ‹ŸçœŸå® API è°ƒç”¨ï¼Œæµ‹é‡ç«¯åˆ°ç«¯å»¶è¿Ÿå’Œååé‡ã€‚

```bash
# å¯åŠ¨æ¨¡å‹æœåŠ¡
vllm serve NousResearch/Hermes-3-Llama-3.1-8B

# æ‰§è¡ŒåŸºå‡†æµ‹è¯•
vllm bench serve \
  --backend vllm \
  --model NousResearch/Hermes-3-Llama-3.1-8B \
  --endpoint /v1/completions \
  --dataset-name sharegpt \
  --dataset-path ./ShareGPT_V3_unfiltered_cleaned_split.json \
  --num-prompts 10
```

**è¾“å‡ºæŒ‡æ ‡åŒ…æ‹¬**ï¼š
- è¯·æ±‚æˆåŠŸç‡ã€æ€»è€—æ—¶
- è¾“å…¥/è¾“å‡º token æ•°é‡
- **è¯·æ±‚ååé‡ï¼ˆreq/sï¼‰**
- **Token ååé‡ï¼ˆtok/sï¼‰**
- **é¦– Token å»¶è¿Ÿï¼ˆTTFTï¼‰**
- **åç»­ Token ç”Ÿæˆå»¶è¿Ÿï¼ˆTPOT / ITLï¼‰**

### 2. ç¦»çº¿ååé‡åŸºå‡†æµ‹è¯•ï¼ˆOffline Throughput Benchmarkï¼‰

é€‚ç”¨äºæ‰¹é‡æ¨ç†åœºæ™¯ï¼Œä¸ä¾èµ–æœåŠ¡è¿›ç¨‹ï¼Œç›´æ¥è°ƒç”¨å¼•æ“ã€‚

```bash
vllm bench throughput \
  --model Qwen/Qwen2-VL-7B-Instruct \
  --backend vllm-chat \
  --dataset-name hf \
  --dataset-path lmarena-ai/VisionArena-Chat \
  --num-prompts 1000
```

> ğŸ“Œ å¯¹äºå¤šæ¨¡æ€æ¨¡å‹ï¼Œè¾“å…¥ token æ•°ä¼šåŒ…å«å›¾åƒ tokenã€‚

### 3. ç»“æ„åŒ–è¾“å‡ºæ€§èƒ½æµ‹è¯•

è¯„ä¼° JSON Schemaã€æ­£åˆ™è¡¨è¾¾å¼ã€è¯­æ³•çº¦æŸç­‰ç»“æ„åŒ–è¾“å‡ºçš„ç”Ÿæˆå¼€é”€ã€‚

```bash
# éœ€å…ˆå¯åŠ¨æœåŠ¡
vllm serve NousResearch/Hermes-3-Llama-3.1-8B

# è¿è¡Œç»“æ„åŒ–è¾“å‡ºåŸºå‡†
python3 benchmarks/benchmark_serving_structured_output.py \
  --backend vllm \
  --model NousResearch/Hermes-3-Llama-3.1-8B \
  --dataset json \
  --structured-output-ratio 1.0 \
  --request-rate 10 \
  --num-prompts 1000
```

æ”¯æŒç±»å‹ï¼š`json`ã€`grammar`ã€`regex`ã€`choice`ã€`xgrammar_bench`ã€‚

### 4. é•¿æ–‡æ¡£ QA ä¸å‰ç¼€ç¼“å­˜ï¼ˆPrefix Cachingï¼‰

æµ‹è¯•åœ¨é‡å¤é•¿ä¸Šä¸‹æ–‡åœºæ™¯ä¸‹ï¼Œå‰ç¼€ç¼“å­˜å¯¹æ€§èƒ½çš„æå‡æ•ˆæœã€‚

```bash
python3 benchmarks/benchmark_long_document_qa_throughput.py \
  --model meta-llama/Llama-2-7b-chat-hf \
  --enable-prefix-caching \
  --num-documents 16 \
  --document-length 2000 \
  --output-len 50 \
  --repeat-count 5
```

æ”¯æŒä¸‰ç§é‡å¤æ¨¡å¼ï¼š`random`ï¼ˆéšæœºï¼‰ã€`tile`ï¼ˆæ•´ä½“å¾ªç¯ï¼‰ã€`interleave`ï¼ˆé€ä¸ªé‡å¤ï¼‰ã€‚

### 5. è¯·æ±‚ä¼˜å…ˆçº§è°ƒåº¦æµ‹è¯•

éªŒè¯é«˜ä¼˜å…ˆçº§è¯·æ±‚æ˜¯å¦èƒ½æ›´å¿«è·å¾—å“åº”ã€‚

```bash
python3 benchmarks/benchmark_prioritization.py \
  --model meta-llama/Llama-2-7b-chat-hf \
  --input-len 128 \
  --output-len 64 \
  --num-prompts 100 \
  --scheduling-policy priority
```

### 6. å¤šæ¨¡æ€ï¼ˆå›¾åƒ/è§†é¢‘ï¼‰æ¨ç†åŸºå‡†

ä»¥ Qwen-VL ä¸ºä¾‹ï¼š

```bash
# å¯åŠ¨å¤šæ¨¡æ€æœåŠ¡
python -m vllm.entrypoints.openai.api_server \
  --model Qwen/Qwen2.5-VL-7B-Instruct \
  --limit-mm-per-prompt '{"image": 1}' \
  --allowed-local-media-path /path/to/images

# å‘é€å¸¦å›¾è¯·æ±‚
vllm bench serve \
  --backend openai-chat \
  --model Qwen/Qwen2.5-VL-7B-Instruct \
  --dataset-name sharegpt \
  --dataset-path /path/to/sharegpt4v.json \
  --num-prompts 100
```

è¿˜æ”¯æŒ**åˆæˆå¤šæ¨¡æ€æ•°æ®**ï¼ˆ`--dataset-name random-mm`ï¼‰ï¼Œç”¨äºå‹åŠ›æµ‹è¯•ã€‚

## äº”ã€é«˜çº§åŠŸèƒ½ä¸æŠ€å·§

### åŠ¨æ€è¯·æ±‚é€Ÿç‡è°ƒèŠ‚ï¼ˆRamp-upï¼‰

æ¨¡æ‹Ÿæµé‡å¢é•¿ï¼Œå¯»æ‰¾ç³»ç»Ÿç“¶é¢ˆï¼š

```bash
vllm bench serve \
  --ramp-up-strategy linear \
  --ramp-up-start-rps 1 \
  --ramp-up-end-rps 50 \
  --duration 60
```

æ”¯æŒ `linear` å’Œ `exponential` ä¸¤ç§ç­–ç•¥ã€‚

### Speculative Decodingï¼ˆæ¨æµ‹è§£ç ï¼‰æµ‹è¯•

ç»“åˆ N-gram æˆ–å°æ¨¡å‹è¿›è¡ŒåŠ é€Ÿï¼š

```bash
VLLM_USE_V1=1 vllm serve meta-llama/Meta-Llama-3-8B-Instruct \
  --speculative-config '{"method": "ngram", "num_speculative_tokens": 5}'

vllm bench throughput \
  --model meta-llama/Meta-Llama-3-8B-Instruct \
  --speculative-config '{"method": "ngram", "num_speculative_tokens": 5}'
```

å®æµ‹å¯æ˜¾è‘—æå‡ååé‡ï¼ˆç¤ºä¾‹ï¼š**104.77 req/s**ï¼‰ã€‚

## å…­ã€ç»“æœä¿å­˜ä¸åˆ†æ

ä½¿ç”¨ä»¥ä¸‹å‚æ•°ä¿å­˜è¯¦ç»†ç»“æœï¼š

```bash
--save-result \
--save-detailed \
--result-dir "./log/"
```

ç»“æœåŒ…å«ï¼š
- æ±‡æ€»ç»Ÿè®¡ï¼ˆMarkdown/JSONï¼‰
- æ¯ä¸ªè¯·æ±‚çš„è¯¦ç»†å»¶è¿Ÿæ•°æ®ï¼ˆCSVï¼‰
- å¯ç”¨äº Grafana/Prometheus ç›‘æ§é›†æˆ

## ä¸ƒã€ç»“è¯­

vLLM çš„åŸºå‡†æµ‹è¯•å·¥å…·ä¸ä»…æ˜¯æ€§èƒ½éªŒè¯çš„åˆ©å™¨ï¼Œæ›´æ˜¯ä¼˜åŒ–æ¨ç†é…ç½®ã€å¯¹æ¯”æ¨¡å‹ç‰ˆæœ¬ã€è¯„ä¼°æ–°åŠŸèƒ½å½±å“çš„**æ ‡å‡†æµç¨‹**ã€‚æ— è®ºä½ æ˜¯éƒ¨ç½²çº¿ä¸ŠæœåŠ¡ï¼Œè¿˜æ˜¯å‚ä¸ vLLM å¼€å‘ï¼ŒæŒæ¡è¿™å¥—å·¥å…·éƒ½å°†æå¤§æå‡ä½ çš„å·¥ä½œæ•ˆç‡ã€‚

> ğŸ“š **å»¶ä¼¸é˜…è¯»**
> - [vLLM å®˜æ–¹æ–‡æ¡£ - Benchmarking](https://docs.vllm.ai/en/stable/contributing/benchmarks.html)
> - [vLLM æ€§èƒ½ä»ªè¡¨ç›˜](https://vllm.ai/performance)
> - [Spec-Bench: ç»“æ„åŒ–æ¨ç†åŸºå‡†](https://github.com/hemingkx/Spec-Bench)
