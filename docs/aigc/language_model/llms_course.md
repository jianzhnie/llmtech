## COS 597G (Fall 2022): Understanding Large Language Models

Large language models (LLMs) have utterly transformed the field of natural language processing (NLP) in the last 3-4 years. They form the basis of state-of-art systems and become ubiquitous in solving a wide range of natural language understanding and generation tasks. With the unprecedented potential and capabilities, these models also give rise to new ethical and scalability challenges. This course aims to cover cutting-edge research topics centering around pre-trained language models. We will discuss their technical foundations (BERT, GPT, T5 models, mixture-of-expert models, retrieval-based models), emerging capabilities (knowledge, reasoning, few-shot learning, in-context learning), fine-tuning and adaptation, system design, as well as security and ethics. We will cover each topic and discuss important papers in depth. Students will be expected to routinely read and present research papers and complete a research project at the end.

This is an advanced graduate course and all the students are expected to have taken machine learning and NLP courses before and are familiar with deep learning models such as Transformers.

### Learning goals:

- This course is intended to prepare you for performing cutting-edge research in natural language processing, especially topics related to pre-trained language models. We will discuss the state-of-the-art, their capabilities and limitations.
- Practice your research skills, including reading research papers, conducting literature survey, oral presentations, as well as providing constructive feedback.
- Gain hands-on experience through the final project, from brainstorming ideas to implementation and empirical evaluation and writing the final paper.

- 

### Useful materials:

- [J & M, slp3](https://web.stanford.edu/~jurafsky/slp3/) is an NLP textbook for you to check out specific topics in NLP.
- [On the Opportunities and Risks of Foundation Models](https://arxiv.org/pdf/2108.07258.pdf) (published by Stanford researchers in July 2021) surveys a range of topics on foundational models (large langauge models are a large part of them).
- [A Primer in BERTology: What we know about how BERT works](https://arxiv.org/pdf/2002.12327.pdf) provides an excellent overview of what we understand about BERT (last update: Nov 2020).

### Schedule

| Topic/papers                                                 | Recommended reading                                          | Presenters                                                   |
| :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| Introduction                                                 | 1. [Human Language Understanding & Reasoning](https://www.amacad.org/sites/default/files/publication/downloads/Daedalus_Sp22_09_Manning.pdf) 2. [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf) (Transformers) 3. [Blog Post: The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) 4. [HuggingFace's course on Transformers](https://huggingface.co/course/chapter1/1) | Danqi Chen [[slides\]](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec01.pdf) |
|                                                              |                                                              |                                                              |
| BERT (encoder-only models) 1. [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf) | 1. [Deep contextualized word representations](https://arxiv.org/pdf/1802.05365.pdf) (ELMo) 2. [Improving Language Understanding by Generative Pre-Training](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf) (OpenAI GPT) 3. [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/pdf/1907.11692.pdf) 4. [ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators](https://arxiv.org/pdf/2003.10555.pdf) | Danqi Chen [[slides\]](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec02.pdf) |
| T5 (encoder-decoder models) 1. [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/pdf/1910.10683.pdf) (T5) | 1. [BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension](https://arxiv.org/pdf/1910.13461.pdf) 2. [mT5: A massively multilingual pre-trained text-to-text transformer](https://arxiv.org/pdf/2010.11934.pdf) 3. [AlexaTM 20B: Few-Shot Learning Using a Large-Scale Multilingual Seq2Seq Model](https://arxiv.org/pdf/2208.01448.pdf) | Abhishek Panigrahi, Victoria Graf [[slides\]](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec03.pdf) |
| GPT-3 (decoder-only models) 1. [Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165.pdf) (GPT-3) | 1. [Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) (GPT-2) 2. [PaLM: Scaling Language Modeling with Pathways](https://arxiv.org/pdf/2204.02311.pdf) 3. [OPT: Open Pre-trained Transformer Language Models](https://arxiv.org/pdf/2205.01068.pdf) | Sabhya Chhabria, Michael Tang [[slides\]](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec04.pdf) |
|                                                              |                                                              |                                                              |
| Prompting for few-shot learning 1. [Making Pre-trained Language Models Better Few-shot Learners](https://arxiv.org/pdf/2012.15723.pdf) ([blog post](https://gaotianyu.xyz/prompting/)) 2. [How Many Data Points is a Prompt Worth?](https://arxiv.org/pdf/2103.08493.pdf) | 1. [Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference](https://arxiv.org/pdf/2001.07676.pdf) 2. [True Few-Shot Learning with Language Models](https://arxiv.org/pdf/2105.11447.pdf) 3. [Cutting Down on Prompts and Parameters: Simple Few-Shot Learning with Language Models](https://arxiv.org/pdf/2106.13353.pdf) 4. [Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing](https://arxiv.org/pdf/2107.13586.pdf) | Kaixuan Huang, Edward Tian [[slides\]](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec05.pdf) |
| Prompting as parameter-efficient fine-tuning 1. [Prefix-Tuning: Optimizing Continuous Prompts for Generation](https://arxiv.org/pdf/2101.00190.pdf) 2. [The Power of Scale for Parameter-Efficient Prompt Tuning](https://arxiv.org/pdf/2104.08691.pdf) | 1. [Factual Probing Is [MASK\]: Learning vs. Learning to Recall](https://arxiv.org/pdf/2104.05240.pdf) 2. [P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks](https://arxiv.org/pdf/2110.07602.pdf) 3. [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/pdf/2106.09685.pdf) 4. [Towards a Unified View of Parameter-Efficient Transfer Learning](https://arxiv.org/pdf/2110.04366.pdf) | Chris Pan, Hongjie Wang [[slides\]](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec06.pdf) |
| In-context learning 1. [Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?](https://arxiv.org/pdf/2202.12837.pdf) 2. [An Explanation of In-context Learning as Implicit Bayesian Inference](https://arxiv.org/pdf/2111.02080.pdf) (we don't expect you to read this paper in depth, you can check out this [blog post](http://ai.stanford.edu/blog/understanding-incontext/) instead) | 1. [What Makes Good In-Context Examples for GPT-3?](https://arxiv.org/pdf/2101.06804.pdf) 2. [Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity](https://arxiv.org/pdf/2104.08786.pdf) 3. [Data Distributional Properties Drive Emergent In-Context Learning in Transformers](https://arxiv.org/pdf/2205.05055.pdf) 4. [What Can Transformers Learn In-Context? A Case Study of Simple Function Classes](https://arxiv.org/pdf/2208.01066.pdf) | Sam Liang, Kexin Jin [[slides\]](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec07.pdf) |
| Calibration of prompting LLMs 1. [Calibrate Before Use: Improving Few-Shot Performance of Language Models](https://arxiv.org/pdf/2102.09690.pdf) 2. [Surface Form Competition: Why the Highest Probability Answer Isnâ€™t Always Right](https://arxiv.org/pdf/2104.08315.pdf) | 1. [Noisy Channel Language Model Prompting for Few-Shot Text Classification](https://arxiv.org/pdf/2108.04106.pdf) 2. [How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering](https://arxiv.org/pdf/2012.00955.pdf) 3. [Language Models (Mostly) Know What They Know](https://arxiv.org/pdf/2207.05221.pdf) | Vishvak Murahari, Howard Yen [[slides\]](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec08.pdf) |
| Reasoning 1. [Chain of Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/pdf/2201.11903.pdf) 2. [Large Language Models are Zero-Shot Reasoners](https://arxiv.org/pdf/2205.11916.pdf) | 1. [Explaining Answers with Entailment Trees](https://arxiv.org/pdf/2104.08661.pdf) 2. [Self-Consistency Improves Chain of Thought Reasoning in Language Models](https://arxiv.org/pdf/2203.11171.pdf) 3. [Faithful Reasoning Using Large Language Models](https://arxiv.org/pdf/2208.14271.pdf) | Zihan Ding, Zixu Zhang [[slides\]](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec09.pdf) |
| Knowledge 1. [Language Models as Knowledge Bases?](https://arxiv.org/pdf/1909.01066.pdf) 2. [How Much Knowledge Can You Pack Into the Parameters of a Language Model?](https://arxiv.org/pdf/2002.08910.pdf) | 1. [Knowledge Neurons in Pretrained Transformers](https://arxiv.org/pdf/2104.08696.pdf) 2. [Fast Model Editing at Scale](https://arxiv.org/pdf/2110.11309.pdf) 3. [Question and Answer Test-Train Overlap in Open-Domain Question Answering Datasets](https://arxiv.org/pdf/2008.02637.pdf) | Jane Pan, Mengzhou Xia [[slides\]](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec10.pdf) |
|                                                              |                                                              |                                                              |
| Data 1. [Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus](https://arxiv.org/pdf/2104.08758.pdf) | 1. [The Pile: An 800GB Dataset of Diverse Text for Language Modeling](https://arxiv.org/pdf/2101.00027.pdf) 2. [Deduplicating Training Data Makes Language Models Better](https://arxiv.org/pdf/2107.06499.pdf) | Andre Niyongabo Rubungo, Tanushree Banerjee [[slides\]](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec11.pdf) |
| Final project proposal due at 11:59pm Submit [here](https://forms.gle/YUfE4m7upopdKxU37). |                                                              |                                                              |
| Fall recess (no class)                                       |                                                              |                                                              |
| Fall recess (no class)                                       |                                                              |                                                              |
| Scaling 1. [Training Compute-Optimal Large Language Models](https://arxiv.org/pdf/2203.15556.pdf) | 1. [Scaling Laws for Neural Language Models](https://arxiv.org/pdf/2001.08361.pdf) 2. [Scale Efficiently: Insights from Pre-training and Fine-tuning Transformers](https://arxiv.org/pdf/2109.10686.pdf) 3. [Scaling Laws for Autoregressive Generative Modeling](https://arxiv.org/pdf/2010.14701.pdf) | Anika Maskara, Simon Park [[slides\]](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec12.pdf) |
| Privacy 1. [Extracting Training Data from Large Language Models](https://arxiv.org/pdf/2012.07805.pdf) | 1. [Quantifying Memorization Across Neural Language Models](https://arxiv.org/pdf/2202.07646.pdf) 2. [Deduplicating Training Data Mitigates Privacy Risks in Language Models](https://arxiv.org/pdf/2202.06539.pdf) 3. [Large Language Models Can Be Strong Differentially Private Learners](https://arxiv.org/pdf/2110.05679.pdf) 4. [Recovering Private Text in Federated Learning of Language Models](https://arxiv.org/pdf/2205.08514.pdf) | Xiangyu Qi, Tong Wu [[slides\]](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec13.pdf) |
| Bias & Toxicity I: evaluation 1. [RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models](https://arxiv.org/pdf/2009.11462.pdf) 2. [OPT paper, Section 4](https://arxiv.org/pdf/2205.01068.pdf) | 1. [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922) 2. [Red Teaming Language Models with Language Models](https://storage.googleapis.com/deepmind-media/Red Teaming/Red Teaming.pdf) 3. [Whose Language Counts as High Quality? Measuring Language Ideologies in Text Data Selection](https://arxiv.org/pdf/2201.10474.pdf) | Maxine Perroni-Scharf, Richard Zhu [[slides\]](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec14.pdf) |
| Bias & Toxicity II: mitigation 1. [Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based Bias in NLP](https://arxiv.org/pdf/2103.00453.pdf) | 1. [Challenges in Detoxifying Language Models](https://arxiv.org/pdf/2109.07445.pdf) 2. [Detoxifying Language Models Risks Marginalizing Minority Voices](https://arxiv.org/pdf/2104.06390.pdf) 3. [Plug and Play Language Models: A Simple Approach to Controlled Text Generation](https://arxiv.org/pdf/1912.02164.pdf) 4. [GeDi: Generative discriminator guided sequence generation](https://arxiv.org/pdf/2009.06367.pdf) | Anirudh Ajith, Arnab Bhattacharjee [[slides\]](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec15.pdf) |
|                                                              |                                                              |                                                              |
| Sparse models 1. [Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://jmlr.org/papers/volume23/21-0998/21-0998.pdf) | 1. [Efficient Large Scale Language Modeling with Mixtures of Experts](https://arxiv.org/pdf/2112.10684.pdf) 2. [Branch-Train-Merge: Embarrassingly Parallel Training of Expert Language Models](https://arxiv.org/pdf/2208.03306.pdf) 3. [A Review of Sparse Expert Models in Deep Learning](https://arxiv.org/pdf/2209.01667.pdf) | Zhou Lu, Wenhan Xia [[slides\]](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec16.pdf) |
| Retrieval-based LMs 1. [Improving language models by retrieving from trillions of tokens](https://arxiv.org/pdf/2112.04426.pdf) | 1. [Generalization through Memorization: Nearest Neighbor Language Models](https://arxiv.org/pdf/1911.00172.pdf) 2. [Training Language Models with Memory Augmentation](https://arxiv.org/pdf/2205.12674.pdf) 3. [Few-shot Learning with Retrieval Augmented Language Models](https://arxiv.org/pdf/2208.03299.pdf) | Tianle Cai, Beiqi Zou [[slides\]](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec17.pdf) |
| Training LMs with human feedback 1. [Training language models to follow instructions with human feedback](https://arxiv.org/pdf/2203.02155.pdf) | 1. [Learning to summarize from human feedback](https://arxiv.org/pdf/2009.01325.pdf) 2. [Fine-Tuning Language Models from Human Preferences](https://arxiv.org/pdf/1909.08593.pdf) 3. [MemPrompt: Memory-assisted Prompt Editing with User Feedback](https://arxiv.org/pdf/2201.06009.pdf) 4. [LaMDA: Language Models for Dialog Application](https://arxiv.org/pdf/2201.08239.pdf) | Howard Chen, Austin Wang [[slides\]](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec18.pdf) |
| Code LMs 1. [Evaluating Large Language Models Trained on Code](https://arxiv.org/pdf/2107.03374.pdf) | 1. [A Conversational Paradigm for Program Synthesis](https://arxiv.org/pdf/2203.13474.pdf) 2. [InCoder: A Generative Model for Code Infilling and Synthesis](https://arxiv.org/pdf/2204.05999.pdf) 3. [A Systematic Evaluation of Large Language Models of Code](https://arxiv.org/pdf/2202.13169.pdf) 4. [Language Models of Code are Few-Shot Commonsense Learners](https://arxiv.org/pdf/2210.07128.pdf) 5. [Competition-Level Code Generation with AlphaCode](https://arxiv.org/pdf/2203.07814.pdf) | Arseniy Andreyev, Jiatong Yu [[slides\]](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec19.pdf) |
| Multimodal LMs 1. [Flamingo: a Visual Language Model for Few-Shot Learning](https://arxiv.org/pdf/2204.14198.pdf) | 1. [Blog post: Generalized Visual Language Models](https://lilianweng.github.io/posts/2022-06-09-vlm/) 2. [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/pdf/2103.00020.pdf) (CLIP) 3. [Multimodal Few-Shot Learning with Frozen Language Models](https://arxiv.org/pdf/2106.13884.pdf) 4. [CM3: A Causal Masked Multimodal Model of the Internet](https://arxiv.org/pdf/2201.07520.pdf) | Andrea Wynn, Xindi Wu [[slides\]](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec20.pdf) |
| Thanksgiving recess (no class)                               |                                                              |                                                              |
| Guest lecture: [Alexander Rush](https://rush-nlp.com/) (Cornell/Hugging Face) Multitask Prompted Training for Zero-Shot Models | 1. [Multitask Prompted Training Enables Zero-Shot Task Generalization](https://arxiv.org/pdf/2110.08207.pdf) 2. [PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts](https://arxiv.org/pdf/2202.01279.pdf) 3. [Scaling Instruction-Finetuned Language Models](https://arxiv.org/pdf/2210.11416.pdf) 4. [Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks](https://arxiv.org/pdf/2204.07705.pdf) |                                                              |
| AI Alignment + open discussion                               | 1. [A General Language Assistant as a Laboratory for Alignment](https://arxiv.org/pdf/2112.00861.pdf) 2. [Alignment of Language Agents](https://arxiv.org/pdf/2103.14659.pdf) 3. [Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback](https://arxiv.org/pdf/2204.05862.pdf) | Devon Wood-Thomas (half of the lecture) [[slides\]](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/lectures/lec22.pdf) |