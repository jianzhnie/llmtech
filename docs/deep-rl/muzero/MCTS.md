# 蒙特卡洛树搜索 (MCTS)

## 什么是 MCTS？

蒙特卡洛树搜索 (MCTS) 是一种在人工智能 (AI) 问题中做出最佳决策的方法，通常是组合游戏中的移动规划。它结合了随机模拟的普遍性和树搜索的精确性。

由于 MCTS 在计算机围棋方面的巨大成功以及对许多其他难题的潜在应用，对 MCTS 的研究兴趣急剧上升。它的应用超越了游戏，理论上MCTS 可以应用于任何可以用 { *state*，*action* } 对和用于预测结果的模拟来描述的领域。

------

## 基本算法

基本的 MCTS 算法很简单：根据模拟播放的结果逐个节点地构建搜索树。该过程可以分解为以下步骤。

![img](https://web.archive.org/web/20180623055344im_/http://mcts.ai/about/mcts-algorithm-1a.png)

- 1. 选择

从根节点*R*开始，递归地选择最佳子节点（如下所述），直到到达叶节点*L。*

- 2. 扩展

如果*L*不是终端节点（即它不会结束游戏），则创建一个或多个子节点并选择一个*C*。

- 3. 模拟

从
*C*运行模拟播放，直到获得结果。

- 4.反向传播

用模拟结果更新当前的移动序列。

每个节点必须包含两条重要信息：基于模拟结果的估计值和访问次数。

在其最简单和内存效率最高的实现中，MCTS 将在每次迭代中添加一个子节点。但是请注意，根据应用程序，每次迭代添加多个子节点可能会有所帮助。

------

## 节点选择

Bandits 和 UCB
树下降过程中的节点选择是通过选择最大化某个数量的节点来实现的，类似于*多臂老虎机问题*，在该问题中，玩家必须选择每轮都最大化估计奖励的老虎机（老虎机）。通常使用以下形式的置信上限 (UCB) 公式：

   ![img](https://web.archive.org/web/20180623055344im_/http://mcts.ai/about/ucb-1.png)

其中*vi*是节点的估计值，*ni是节点*被访问的次数，*N*是其父节点被访问的总次数*。C*是可调偏置参数。

### 开发与探索

UCB 公式平衡了已知奖励的开发与相对未访问节点的*探索*以鼓励他们的锻炼*。*奖励估计是基于随机模拟，因此在这些估计变得可靠之前必须多次访问节点；MCTS 估计在搜索开始时通常是不可靠的，但在给定足够时间的情况下会收敛到更可靠的估计，并在给定无限时间的情况下收敛到更可靠的估计。

### MCTS 和 UCT

Kocsis 和 Szepervari (2006) 首先通过将 UCB 扩展到极小极大树搜索来形式化完整的 MCTS 算法，并将其命名为树的置信上限 (UCT) 方法。这是绝大多数当前 MCTS 实现中使用的算法。

UCT可以描述为MCTS的一个特例，即：UCT = MCTS + UCB。

------

## 优势

与传统的树搜索方法相比，MCTS 具有许多优势。

### 启发式

MCTS 不需要任何关于给定领域的战略或战术知识来做出合理的决定。该算法可以在除了合法移动和结束条件之外的游戏知识的情况下有效运行；这意味着一个单一的 MCTS 实现可以在稍作修改的情况下重复用于许多游戏，并使 MCTS 成为一般游戏的潜在福音。

### 非对称

MCTS 执行适应搜索空间拓扑的非对称树生长。该算法更频繁地访问更有趣的节点，并将其搜索时间集中在树的更相关部分。

![img](https://web.archive.org/web/20180623055344im_/http://mcts.ai/mcts-tree-4.png)

这使得 MCTS 适用于分支因子较大的游戏，例如 19x19 的围棋。如此大的组合空间通常会导致标准的基于深度或广度的搜索方法出现问题，但 MCTS 的自适应特性意味着它将（最终）找到那些看起来最优的移动并将其搜索工作集中在那里。

### Anytime

可以随时停止算法以返回当前最佳估计值。到目前为止构建的搜索树可能会被丢弃或保留以供将来重用。

### 优雅

该算法易于实现（请参阅[代码](https://web.archive.org/web/20180623055344/http://mcts.ai/code/index.html)）。

------

## 缺点

MCTS 有一些缺点，但它们可能是主要的。

### 发挥实力

即使是中等复杂度的游戏，MCTS 算法的基本形式也无法在合理的时间内找到合理的着法。这主要是由于组合移动空间的巨大规模以及关键节点可能没有被访问足够多次以提供可靠估计的事实。

### 速度

MCTS 搜索可能需要多次迭代才能收敛到一个好的解决方案，这对于难以优化的更通用的应用程序来说可能是一个问题。例如，最好的围棋实施可能需要数百万次的比赛，并结合领域特定的优化和增强功能，才能做出专家级的举动，而最好的 GGP 实施可能每秒只能进行数十次（独立于领域的）比赛，以应对更复杂的游戏。对于合理的移动时间，此类 GGP 可能几乎没有时间访问每个合法移动，并且不太可能进行重大搜索。

幸运的是，可以使用多种技术显着提高算法的性能。

------

## 改进

迄今为止，已经提出了数十项 MCTS 增强功能。这些通常可以描述为领域知识或领域独特性。

### 领域知识

特定于当前游戏的领域知识可以在树中被利用来过滤掉不可信的动作，或者在模拟中产生更类似于人类对手之间发生的比赛的*大量比赛。*这意味着播出结果将比随机模拟更真实，并且节点将需要更少的迭代来产生真实的奖励值。

领域知识可以产生显着的改进，但代价是速度和通用性的丧失。

### 域独立

域独立增强适用于所有问题域。这些通常应用于树中（例如 AMAF），尽管有些再次应用于模拟（例如更喜欢在播出期间获胜的动作）。域独立增强不将实现绑定到特定域，保持通用性，因此是该领域大多数当前工作的重点。

------

##  Context

1928 年： John von Neumann 的极小极大定理为对抗树搜索方法铺平了道路，这些方法几乎从一开始就构成了计算机科学和人工智能决策的基础。

1940 年代：蒙特卡洛 (MC) 方法被形式化为一种通过使用随机抽样来处理不适合树搜索的不太明确的问题的方法。

2006 年： Rémi Coulomb 和其他研究人员将这两个想法结合起来，提供了一种在计算机围棋中进行移动规划的新方法，现在称为 MCTS。Kocsis 和 Szepesvári 将这种方法形式化为 UCT 算法。

这种优雅的算法没有早点被发现，这似乎很了不起！