
## 第 17 章 注意力机制与多智能体强化学习

注意力机制 (attention) 是一种重要的深度学习方法, 它最主要的用途是自然语言处 理, 比如机器翻译、情感分析。本章的目的不是详细解释注意力机制的原理, 而是它在多 智能体强化学习 (MARL) 中的应用。第 $17.1$ 节简单介绍自注意力机制 (self-attention), 它是一种特殊的注意力机制。第 $17.2$ 节将自注意力机制应用在 MARL, 改进中心化训练 或中心化决策。当智能体数量 $m$ 较大时, 自注意力机制对 MARL 有明显的效果提升。

## $17.1$ 自注意力机制

注意力机制 (attention) 最初用于改进循环神经网络 (RNN), 提高 sequence-to-sequence (seq2seq) 模型的表现。自注意力机制 (self-attention) 是注意力机制的一种扩展, 不局限 于 seq2seq 模型, 可以用于任意的 RNN。后来 Transformer 模型将 RNN 剥离, 只保留注 意力机制。与 RNN + 注意力机制相比, 只用注意力机制居然表现更好, 在机器翻译等任 务上的效果有大幅提升。本节不深入讨论注意力机制与 RNN、seq2seq 之间的关系, 而只 介绍本章所需的一些知识点。

考虑这样一个问题：输入是长度 为 $m$ 的序列 $\left(\boldsymbol{x}^{1}, \cdots, \boldsymbol{x}^{m}\right)$, 序列中的 元素都是向量, 要求输出长度同样为 $m$ 的序列 $\left(\boldsymbol{c}^{1}, \cdots, \boldsymbol{c}^{m}\right)$; 如图 $17.1$ 所 示。问题还有两个要求:

- 第一, 序列的长度 $m$ 是不确定 的, 可以动态变化。但是神经网 络的参数数量不能变化。

- 第二, 输出的向量 $\boldsymbol{c}^{i}$ 不是仅仅 依赖于向量 $\boldsymbol{x}^{i}$, 而是依赖于所

![](https://cdn.mathpix.com/cropped/2023_02_03_f46f5cf0e4de5b9996dcg-265.jpg?height=491&width=734&top_left_y=1348&top_left_x=912)

图 17.1: 将一个长度为 $m$ 的向量序列映射到另一个同 等长度的向量序列。 有的输入向量 $\left(\boldsymbol{x}^{1}, \cdots, \boldsymbol{x}^{m}\right)$ 。

可以用简单的全连接网络逐个把向量 $\boldsymbol{x}^{i}$ 映射到 $\boldsymbol{c}^{i}$, 但是这样得到的 $\boldsymbol{c}^{i}$ 仅依赖于 $\boldsymbol{x}^{i}$ 一个 向量而已, 不满足第二个要求。第 13 章介绍的 RNN 也不满足第二个要求; RNN 输出的 向量 $\boldsymbol{c}^{i}$ 只依赖于 $\left(\boldsymbol{x}^{1}, \cdots, \boldsymbol{x}^{i}\right)$, 而不依赖于 $\left(\boldsymbol{x}^{i+1}, \cdots, \boldsymbol{x}^{m}\right)$ 。

自注意力层 (self-attention layer) 可以解决上述问题。如图 $17.2$ 所示, 自注意力层的 输入是序列 $\left(\boldsymbol{x}^{1}, \cdots, \boldsymbol{x}^{m}\right)$, 其中的向量的大小都是 $d_{\mathrm{in}} \times 1$ 。自注意力层有三个参数矩阵:

$$
\boldsymbol{W}_{q} \in \mathbb{R}^{d_{q} \times d_{\text {in }}}, \quad \boldsymbol{W}_{k} \in \mathbb{R}^{d_{q} \times d_{\text {in }}}, \quad \boldsymbol{W}_{v} \in \mathbb{R}^{d_{\text {out }} \times d_{\text {in }}} .
$$

序列长度 $m$ 不会影响参数的数量。不论序列有多长, 参数矩阵只有 $\boldsymbol{W}_{q}, \boldsymbol{W}_{k}, \boldsymbol{W}_{v}$ 。这三 个参数矩阵需要从训练数据中学习。自注意力层通过以下步骤, 把输入序列 $\left(\boldsymbol{x}^{1}, \cdots, \boldsymbol{x}^{m}\right)$ 映射到输出序列 $\left(\boldsymbol{c}^{1}, \cdots, \boldsymbol{c}^{m}\right)$, 输出向量的大小都是 $d_{\text {out }} \times 1$ 。

![](https://cdn.mathpix.com/cropped/2023_02_03_f46f5cf0e4de5b9996dcg-266.jpg?height=237&width=1239&top_left_y=407&top_left_x=471)

图 17.2: 首先把 $\boldsymbol{x}^{i}$ 映射到三元组 $\left(\boldsymbol{q}^{i}, \boldsymbol{k}^{i}, \boldsymbol{v}^{i}\right), \forall i=1, \cdots, m$ 。

![](https://cdn.mathpix.com/cropped/2023_02_03_f46f5cf0e4de5b9996dcg-266.jpg?height=543&width=1224&top_left_y=1028&top_left_x=473)

图 17.3: 然后用 $\boldsymbol{q}^{i}$ 和 $\left(\boldsymbol{k}^{1}, \cdots, \boldsymbol{k}^{m}\right)$ 计算权重向量 $\boldsymbol{\alpha}^{i} \in \mathbb{R}^{m}, \forall i=1, \cdots, m$ 。

![](https://cdn.mathpix.com/cropped/2023_02_03_f46f5cf0e4de5b9996dcg-266.jpg?height=540&width=1226&top_left_y=1926&top_left_x=472)

图 17.4: 最后用 $\boldsymbol{\alpha}^{i}$ 和 $\left(\boldsymbol{v}^{1}, \cdots, \boldsymbol{v}^{m}\right)$ 计算输出向量 $\boldsymbol{c}^{i} \in \mathbb{R}^{d_{\text {out }}}, \forall i=1, \cdots, m$ 。 1. 如图 $17.2$ 所示, 对于所有的 $i=1, \cdots, m$, 把输入的 $\boldsymbol{x}^{i}$ 映射到三元组 $\left(\boldsymbol{q}^{i}, \boldsymbol{k}^{i}, \boldsymbol{v}^{i}\right)$ :

$$
\begin{aligned}
\boldsymbol{q}^{i} & =\boldsymbol{W}_{q} \boldsymbol{x}^{i} \in \mathbb{R}^{d_{q}}, \\
\boldsymbol{k}^{i} & =\boldsymbol{W}_{k} \boldsymbol{x}^{i} \in \mathbb{R}^{d_{q}}, \\
\boldsymbol{v}^{i} & =\boldsymbol{W}_{v} \boldsymbol{x}^{i} \in \mathbb{R}^{d_{\text {out }}} .
\end{aligned}
$$

2. 如图 $17.3$ 所示, 计算权重向量 $\left(\boldsymbol{\alpha}^{1}, \cdots, \boldsymbol{\alpha}^{m}\right)$, 每个权重向量的大小都是 $m \times 1$ 。第 $i$ 个权重向量 $\boldsymbol{\alpha}^{i}$ 依赖于 $\boldsymbol{q}^{i}$ 和 $\left(\boldsymbol{k}^{1}, \cdots, \boldsymbol{k}^{m}\right)$ :

$$
\boldsymbol{\alpha}^{i}=\operatorname{softmax}\left(\left\langle\boldsymbol{q}^{i}, \boldsymbol{k}^{1}\right\rangle,\left\langle\boldsymbol{q}^{i}, \boldsymbol{k}^{2}\right\rangle, \cdots,\left\langle\boldsymbol{q}^{i}, \boldsymbol{k}^{m}\right\rangle\right), \quad \forall i=1, \cdots, m .
$$

公式中的 $\langle\cdot, \cdot\rangle$ 是向量内积。由于向量 $\boldsymbol{\alpha}^{i}$ 是 softmax 函数的输出, 它的元素都是 正实数, 而且相加等于 1 。向量 $\boldsymbol{\alpha}^{i}$ 的第 $j$ 个元素（记作 $\alpha_{j}^{i}$ ) 表示 $\boldsymbol{x}_{i}$ 与 $\boldsymbol{x}_{j}$ 的相关 性; $\boldsymbol{x}_{i}$ 与 $\boldsymbol{x}_{j}$ 越相关，那么元素 $\alpha_{j}^{i}$ 就越大。

3. 如图 $17.4$ 所示, 计算输出向量 $\left(\boldsymbol{c}^{1}, \cdots, \boldsymbol{c}^{m}\right)$, 每个输出向量的维度都是 $d_{\text {out }}$ 。第 $i$ 个输出向量 $\boldsymbol{c}^{i}$ 依赖于 $\boldsymbol{\alpha}^{i}$ 和 $\left(\boldsymbol{v}^{1}, \cdots, \boldsymbol{v}^{m}\right)$ :

$$
\boldsymbol{c}^{i}=\left[\boldsymbol{v}^{1}, \boldsymbol{v}^{2}, \cdots, \boldsymbol{v}^{m}\right] \cdot \boldsymbol{\alpha}^{i}=\sum_{j=1}^{m} \alpha_{j}^{i} \boldsymbol{v}^{j}, \quad \forall i=1, \cdots, m .
$$

$\boldsymbol{c}^{i}$ 是向量 $\boldsymbol{v}^{1}, \cdots, \boldsymbol{v}^{m}$ 的加权平均, 权重是 $\boldsymbol{\alpha}^{i}=\left[\alpha_{1}^{i}, \cdots, \alpha_{m}^{i}\right]$ 。

为什么这种神经网络结构叫做 注意力 (attention) 呢? 如图 $17.5$ 所 示, 向量 $\boldsymbol{x}^{i}$ 位置上的输出是 $\boldsymbol{c}^{i}$, 它 是做加权平均计算出来的:

$\boldsymbol{c}^{i}=\alpha_{1}^{i} \boldsymbol{v}^{1}+\alpha_{2}^{i} \boldsymbol{v}^{2}+\cdots+\alpha_{m}^{i} \boldsymbol{v}^{m}$.

权重 $\boldsymbol{\alpha}^{i}=\left[\alpha_{1}^{i}, \cdots, \alpha_{m}^{i}\right]$ 反映出 $\boldsymbol{c}^{i}$ 最 “关注” 哪些输入的 $\boldsymbol{v}^{j}=\boldsymbol{W}_{v} \boldsymbol{x}^{j}$ 。 如果权重 $\alpha_{j}^{i}$ 大, 说明 $\boldsymbol{x}^{j}$ 对 $\boldsymbol{c}^{i}$ 的影 响较大。 $c^{i}$ 应当重点关注对其影响 较大的 $\boldsymbol{x}^{j}$ 。

![](https://cdn.mathpix.com/cropped/2023_02_03_f46f5cf0e4de5b9996dcg-267.jpg?height=546&width=700&top_left_y=1343&top_left_x=929)

图 17.5: 第 $i$ 个输出向量 $\boldsymbol{c}^{i}$ 由权重 $\boldsymbol{\alpha}^{i}=\left[\alpha_{1}^{i}, \cdots, \alpha_{m}^{i}\right]$ 和 向量 $\left(\boldsymbol{v}^{1}, \cdots, \boldsymbol{v}^{m}\right)$ 决定。

上述自注意力层叫做单头自注意力层 (Single-Head Self-Attention Layer), 简称“单头”。 实践中更常用的是多头自注意力层 (Multi-Head Self-Attention Layer), 简称 “多头”, 它是多 个单头的组合, 见图 17.6。设多头由 $l$ 个单头组成。每个单头有自己的 3 个参数矩阵, 所 以多头一共有 $3 l$ 个参数矩阵。它们的输入都是序列 $\left(\boldsymbol{x}_{1}, \cdots, \boldsymbol{x}_{m}\right)$, 它们的输出都是长度 为 $m$ 的向量序列。

$$
\begin{array}{cc}
\text { 第 } 1 \text { 个自注意力层输出: } & \left(\boldsymbol{c}_{1}^{1}, \boldsymbol{c}_{1}^{2}, \boldsymbol{c}_{1}^{3}, \cdots, c_{1}^{m}\right), \\
\text { 第 } 2 \text { 个自注意力层输出: } & \left(\boldsymbol{c}_{2}^{1}, \boldsymbol{c}_{2}^{2}, \boldsymbol{c}_{2}^{3}, \cdots, c_{2}^{m}\right), \\
\vdots & \vdots \\
\text { 第 } l \text { 个自注意力层输出 : } & \left(c_{l}^{1}, \boldsymbol{c}_{l}^{2}, \boldsymbol{c}_{l}^{3}, \cdots, c_{l}^{m}\right) .
\end{array}
$$

其中每个向量 $\boldsymbol{c}_{j}^{i}$ 的大小都是 $d_{\mathrm{out}} \times 1$ 。多头的输出记作序列 $\left(\boldsymbol{c}^{1}, \cdots, \boldsymbol{c}^{m}\right)$, 其中每个 $\boldsymbol{c}^{i}$ 都 是做连接 (concatenation) 得到的:

$$
\boldsymbol{c}^{i}=\left[\boldsymbol{c}_{1}^{i} ; \boldsymbol{c}_{2}^{i} ; \cdots ; \boldsymbol{c}_{l}^{i}\right] \in \mathbb{R}^{l d_{\text {out }}}, \quad \forall i=1, \cdots, m .
$$

![](https://cdn.mathpix.com/cropped/2023_02_03_f46f5cf0e4de5b9996dcg-268.jpg?height=771&width=1442&top_left_y=548&top_left_x=361)

图 17.6: 这个例子中, 多头自注意力层由 $l=4$ 个单头自注意力层组成。

总结一下, 多头自注意力层把长度为 $m$ 的向量序列映射到同等长度的向量序列。长 度 $m$ 可以任意变化, 神经网络结构无需改变。实现一个多头自注意力层需要指定三个超 参数：单头的数量l、每个单头输出的大小 $d_{\text {out }}$ 、向量 $\boldsymbol{q}^{i}$ 和 $\boldsymbol{k}^{i}$ 的大小 $d_{q}$ 。多头的输出是 长度为 $m$ 的向量序列, 每个向量的大小是 $l d_{\mathrm{out}} \times 1$ 。超参数 $d_{q}$ 不影响输出的大小, 它只 在计算权重向量 $\boldsymbol{\alpha}^{1}, \cdots, \boldsymbol{\alpha}^{m}$ 的时候使用。

## $17.2$ 自注意力在中心化训练中的应用

自注意力机制 (self-attention) 是改进多智能体强化学习（MARL）的一种有效技巧, 可以应用在中心化训练或中心化决策当中。自注意力机制在 MARL 中有不同的用法。此 处只讲解一种用法, 帮助大家理解自注意力在 MARL 中的意义。

多智能体系统中有 $m$ 个智能体, 每个智能体有自己的观测（记作 $o^{1}, \cdots, o^{m}$ ) 和动 作（记作 $\left.a^{1}, \cdots, a^{m}\right)$ 。我们考虑非合作关系的 MARL。如果做中心化训练, 需要用到 $m$ 个状态价值网络

$$
v\left(\left[o^{1}, \cdots, o^{m}\right] ; \boldsymbol{w}^{1}\right), \quad \cdots, \quad v\left(\left[o^{1}, \cdots, o^{m}\right] ; \boldsymbol{w}^{m}\right),
$$

或 $m$ 个动作价值网络

$$
q\left(\left[o^{1}, \cdots, o^{m}\right],\left[a^{1}, \cdots, a^{m}\right] ; \boldsymbol{w}^{1}\right), \quad \cdots, \quad q\left(\left[o^{1}, \cdots, o^{m}\right],\left[a^{1}, \cdots, a^{m}\right] ; \boldsymbol{w}^{m}\right) .
$$

由于是非合作关系, $m$ 个价值网络有各自的参数, 而且它们的输出各不相同。我们首先 以状态价值网络 $v$ 为例讲解神经网络的结构。

不使用自注意力的状态价值网 络：图 $17.7$ 是状态价值网络 $v\left(s ; \boldsymbol{w}^{i}\right)$ 最简单的实现。每个价值网络是一个 独立的神经网络, 有自己的参数。底 层提取特征的卷积网络可以在 $m$ 个价 值网络中共享 (即复用), 而上层的全 连接网络不能共享。神经网络的输入 是所有智能体的观测的连接 (concatenation), 输出是实数

$$
\widehat{v}^{i}=v\left(\left[o^{1}, \cdots, o^{m}\right] ; \boldsymbol{w}^{i}\right) .
$$

这种简单的神经网络结构有几个不足 之处。

- 智能体数量 $m$ 越大, 神经网络 的参数越多。神经网络的输入是 $m$ 个观测的连接, 它们被映射到
![](https://cdn.mathpix.com/cropped/2023_02_03_f46f5cf0e4de5b9996dcg-269.jpg?height=858&width=734&top_left_y=1208&top_left_x=954)

图 17.7: 第 $i$ 号状态价值网络最简单的实现。 特征向量 $\boldsymbol{x} 。 m$ 越大, 我们就必 须把向量 $\boldsymbol{x}$ 维度设置得越大，否则 $\boldsymbol{x}$ 无法很好地概括 $\left[o^{1}, \cdots, o^{m}\right]$ 的完整信息。 $\boldsymbol{x}$ 维度越大, 全连接网络的参数就越多, 神经网络就越难训练 (即需要收集更多的经 验才能训练好神经网络)。

- 当 $m$ 很大的时候, 并非所有智能体的观测 $o^{1}, \cdots, o^{m}$ 都与第 $i$ 号智能体密切相关。 第 $i$ 号智能体应当学会判断哪些智能体最相关, 并重点关注密切相关的智能体, 避 免决策受无关的智能体干扰。

使用自注意力的状态价值网络：图 $17.8$ 是对状态价值网络更好的实现方式, 避免了 上面讨论的三种不足之处。神经网络的结构是这样的:

- 输入仍然是所有智能体的观测 $o^{1}, \cdots, o^{m}$ 。对于所有的 $i$, 用一个卷积网络把 $o^{i}$ 映 射到特征向量 $\boldsymbol{x}^{i}$ 。这些卷积网络的参数都是相同的。

- 自注意力层的输入是向量序列 $\left(\boldsymbol{x}^{1}, \cdots, \boldsymbol{x}^{m}\right)$, 输出是序列 $\left(\boldsymbol{c}^{1}, \cdots, \boldsymbol{c}^{m}\right)$ 。向量 $\boldsymbol{c}^{i}$ 依 赖于所有的观测 $\boldsymbol{x}^{1}, \cdots, \boldsymbol{x}^{m}$ ，但是 $\boldsymbol{c}^{i}$ 主要取决于最密切相关的一个或几个 $\boldsymbol{x}$ 。

- 第 $i$ 号全连接网络把向量 $\boldsymbol{c}^{i}$ 作为输入, 输出一个实数 $\widehat{v}^{i}$, 作为第 $i$ 号价值网络的输 出。在非合作关系的设定下, $m$ 个价值网络是不同的, 因此 $m$ 个全连接网络不共 享参数。

图 $17.8$ 中只用了一个自注意力层。其实可以重复自注意力层, 比如:

$\cdots \longrightarrow$ 自注意力层 $\longrightarrow$ 全连接层 $\longrightarrow$ 自注意力层 $\longrightarrow$ 全连接层 $\longrightarrow \cdots$

自注意力的层数是一个超参数, 需要用户自己调。

![](https://cdn.mathpix.com/cropped/2023_02_03_f46f5cf0e4de5b9996dcg-270.jpg?height=1056&width=1442&top_left_y=1017&top_left_x=361)

图 17.8: 带有自注意力的状态价值网络。图中的 $\widehat{v}^{i}=v\left(\left[o^{1}, \cdots, o^{m}\right] ; \boldsymbol{w}^{i}\right)$ 是第 $i$ 个价值网络的输 出。

使用自注意力的动作价值网络：上一章介绍了 MADDPG, 它是一种连续控制方法, 用于非合作关系的设定。它的架构是“中心化训练 + 去中心化决策”, 在中央控制器上部 署 $m$ 个动作价值网络, 把第 $i$ 个记作：

$$
\widehat{q}^{i}=q\left(\left[o^{1}, \cdots, o^{m}\right],\left[\boldsymbol{a}^{1}, \cdots, \boldsymbol{a}^{m}\right] ; \boldsymbol{w}^{i}\right) .
$$

它的输入是所有智能体的观测和动作, 输出是实数 $\widehat{q}^{i}$, 表示动作价值。可以按照图 $17.9$ 实现动作价值网络。在 MADDPG 中使用这样的神经网络结构可以提高 MADDPG 的表 现, 尤其是当 $m$ 较大的时候, 效果的提升较大。

![](https://cdn.mathpix.com/cropped/2023_02_03_f46f5cf0e4de5b9996dcg-271.jpg?height=1070&width=1433&top_left_y=356&top_left_x=240)

图 17.9: 带有自注意力的动作价值网络。图中的 $\widehat{q}^{i}=q\left(\left[o^{1}, \cdots, o^{m}\right],\left[a^{1}, \cdots, a^{m}\right] ; \boldsymbol{w}^{i}\right)$ 是第 $i$ 个动 作价值网络的输出。

使用自注意力的中心化策略网络：对于 “中心化训练 + 中心化决策”的系统架构, 需 要在中央控制器上部署 $m$ 个策略网络, 每个策略网络都需要知道所有 $m$ 个智能体的观 测 $o^{1}, \cdots, o^{m}$ 。

- 对于离散控制, 第 $i$ 号策略网络记作：

$$
\widehat{\boldsymbol{f}}^{i}=\pi\left(\cdot \mid\left[o^{1}, \cdots, o^{m}\right] ; \boldsymbol{\theta}^{i}\right) .
$$

策略网络的输出是向量 $\widehat{\boldsymbol{f}}^{i}$, 它的维度是第 $i$ 号动作空间的大小 $\left|\mathcal{A}^{i}\right|, \widehat{\boldsymbol{f}}^{i}$ 的元素表示 每种动作的概率。根据 $\widehat{\boldsymbol{f}}^{i}$ 做随机抽样, 得到动作 $a^{i}$, 第 $i$ 号智能体执行这个动作。

-对于连续控制, 第 $i$ 号策略网络记作：

$$
\boldsymbol{a}^{i}=\boldsymbol{\mu}\left(\left[o^{1}, \cdots, o^{m}\right] ; \boldsymbol{\theta}^{i}\right) .
$$

它的输出是动作 $\boldsymbol{a}^{i}$, 它是 $d$ 维向量, $d$ 是连续控制问题的自由度。第 $i$ 号智能体执 行动作 $\boldsymbol{a}^{i}$ 。

不管是离散控制还是连续控制, 上述两种策略网络中都可以使用自注意力层, 神经网络 的结构与图 $17.8$ 中的 $v\left(s ; \boldsymbol{w}^{i}\right)$ 几乎一样, 唯一区别是神经网络的输出由实数 $\widehat{v}^{1}, \cdots, \widehat{v}^{m}$ 变成向量 $\widehat{\boldsymbol{f}}^{1}, \cdots, \widehat{\boldsymbol{f}}^{m}$ 或者 $\boldsymbol{a}^{1}, \cdots, \boldsymbol{a}^{m}$ 。 总结：自注意力机制在非合作关系的 MARL 中普遍适用。如果系统架构使用中心 化训练, 那么 $m$ 个价值网络可以用一个神经网络实现, 其中使用自注意力层。如果系统 架构使用中心化决策, 那么 $m$ 个策略网络也可以实现成一个神经网络, 其中使用自注意 力层。在 $m$ 较大的情况下, 使用自注意力层对效果有较大的提升。

## 第 17 章 知识点

- 自注意力层的输入是向量序列 $\boldsymbol{x}^{1}, \cdots, \boldsymbol{x}^{m}$, 输出是向量序列 $\boldsymbol{c}^{1}, \cdots, \boldsymbol{c}^{m}$ 。两个序列 的长度相同, 但是向量的维度可以不同。自注意力层的参数数量与序列长度 $m$ 无 关, 因此序列的长度可以任意。

- 自注意力层的输入与输出的关系是多对多。输出向量 $\boldsymbol{c}^{i}$ 不止依赖于 $\boldsymbol{x}^{i}$, 而且依赖 于所有的输入。改变任意一个输入向量, 都会影响输出的 $\boldsymbol{c}^{i}$ 。

-多头自注意力层由 $l$ 个独立的单头自注意力层组成, $l$ 的大小任意。把单头的输出 做连接, 作为多头的输出。如果每个单头自注意力层有 $n$ 个参数, 那么多头自注意 力层就有 $n \times l$ 个参数。

。在做中心化训练或中心化决策的时候, 可以将自注意力层用于价值网络或策略网 络, 把所有智能体的观测作为输入序列。

## 第 17 章 相关文献

注意力机制 (attention) 由 2015 年的论文 ${ }^{[6]}$ 提出; 这篇论文将注意力机制与 RNN

结合, 大幅提升 RNN 在机器翻译任务上的表现。2017 年的论文 ${ }^{[118]}$ 提出 Transformer 模型, 去掉 RNN, 只保留注意力, 在机器翻译任务上取得了远优于 RNN 加注意力的表 现。2019 年的论文 ${ }^{[56]}$ 将注意力层用到多智能体的 actor-critic 中。
