# 数据并行

## 问题分析

对于数据集过大的模型训练场景，其训练时间过长，要将数据集进行切分，让一个计算设备只处理一部分数据。

## 解决方案

数据并行将数据集切分为多个batch，并且均分给不同计算设备。每个计算设备只负责处理自己的batch。
数据并行满足：
1.每个设备上模型的组网和参数相同。
2.每个设备处理不同batch的数据。

### 解决思路

1.每个计算设备上都存储一份完整的模型副本。
2.数据集被切分为多个batch，并且平均分给不同的计算设备，各计算设备处理不同的数据。
3.前向计算完成得到梯度之后，需要通过all-reduce操作将各计算设备得到的梯度取平均后再发给各计算设备，保证各计算设备的参数保持一致。

## 使用场景

训练数据集过大，训练时间过长，且可用于训练的计算设备比较充足，可以存储多份完整模型，可以开启数据并行，来加快训练速度，减轻单设备的计算压力。

## 使用方法

框架中数据并行通过总设备数(world_size)、模型并行数(tensor_model_parallel_size)、流水线并行数(pipeline_model_parallel_size)、长序列并行数(context_parallel_size)计算得到。
数据并行数(data_parallel_size) = world_size // (tensor_model_parallel_size * pipeline_model_parallel_size * context_parallel_size)

## 使用效果

利用多个设备，增加了总的显存占用量，但是加快了训练速度，减轻了单设备的计算压力。
