# PP支持动态形状

## 背景与挑战

在深度学习模型训练中，尤其是涉及多模态任务时，输入数据的序列长度往往不是固定的。对于采用流水线并行（Pipeline Parallelism, PP）策略的模型，
处理不同长度的序列通常需要将所有序列调整为统一长度，通过填充或截断来实现。这种做法虽然简化了数据处理和模型设计，但会导致计算资源和内存的浪费，特别是在处理较短序列时，因为需要大量的填充。
**主要挑战：**
- **内存效率低下**：可能存在大量填充导致内存利用率低。
- **计算效率低下**：对填充部分进行不必要的计算。

## 解决方案

为了应对上述挑战，我们引入了对动态形状的支持，允许每个微批次中的序列保持其原始长度。此功能通过在发送张量之前，提前通信张量的形状信息，在各个流水线阶段之间同步即将接收的数据形状，确保内存分配和预处理的准确性。
## 使用场景

- **多变长度文本处理**：如文档分类、机器翻译等任务，其中文本长度差异很大。
- **增强模型泛化能力**：让模型更好地适应各种长度的输入，从而提高其在实际应用中的表现。

## 使用方法

**注意事项：**
- 当采用流水线并行策略且序列长度固定时，启用该特性将增加不必要的通信开销，因此不建议使用。
- 密切监控训练过程中的内存消耗，避免因序列长度变动引起的溢出问题。

**设置训练脚本参数**
```shell
# 开启流水线并行, PP >= 2
--pipeline-model-parallel-size ${PP} \
# 开启PP支持动态形状
--variable-seq-lengths
```
限制条件：
1. 暂不支持 `--moe-token-dispatcher-type alltoall_seq`和`--moe-token-dispatcher-type allgather`

## 使用效果

- **优化资源利用**：与传统方法中所有序列需填充至统一长度相比，本方案通过减少不必要的填充操作，有效节省内存空间，降低计算负载，提高整体性能。
- **提高灵活性**：该特性赋予模型更强的适应性，使其能够高效处理各种长度的输入数据，进而增强了模型的泛化能力。这对于需要处理变长输入的任务（如文本分类、机器翻译等）尤为重要。
- **更真实的数据表示**：保留了原始文本的真实长度，有助于模型更准确地捕捉文本特征。
- **潜在性能影响**：尽管有诸多优点，但在某些情况下（如开启流水线并行，并且原序列为等长或需被截断以保持一致长度时），启用该特性可能会增加复杂度并减慢训练速度。因此，在设计和部署时应综合考虑这些因素，确保系统整体性能最优化。

综上所述，PP支持动态形状是针对特定应用场景的一种有效优化手段，它能够在保证模型性能的同时，显著改善资源利用率和数据处理的灵活性。用户应根据实际情况权衡利弊，决定是否启用这一特性。
