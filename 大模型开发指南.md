# Ascend 开发环境配置与操作指南

## 环境配置

### CANN 环境配置

加载 CANN 环境变量，路径需根据实际安装位置进行调整：
```bash
install_path=/usr/local/Ascend
source $install_path/ascend-toolkit/set_env.sh
source $install_path/nnal/atb/set_env.sh
```

### 检查 NPU 状态

运行以下命令以检查 NPU 状态：
```bash
npu-smi info
```

###  安装 torch & torch-npu

```bash
pip install numpy==1.26.0
pip install torch==2.5.1 && pip install torch-npu==2.5.1rc1
```

### PIP 下载源

```bash
# tsinghua 源
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple --trusted-host pypi.tuna.tsinghua.edu.cn numpy==1.26.0

# aliyun 源
pip install -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com numpy==1.26.0
```

### 挂载数据存储

挂载分布式持久化存储（DPC）：
```bash
mount -t dpc /cloudbrain-llm-datasets llm_dataset
mount -t dpc /shared_dpc grpo
```

### 修改文件权限

修改 Miniconda 文件夹的权限：
```bash
chown -R HwHiAiUser:users miniconda3/
chmod -R 755 miniconda3/
```

### 登录 wandb

登录 wandb，用于实验跟踪与可视化：
```bash
wandb login 8ad58a961091cd50e8ed0b00d9060e502209a2b5
```



## 代码与资源获取

### 使用 GitHub 代理

为了加速 GitHub 文件的下载，可以使用 [GitHub 文件加速代理](https://gh-proxy.com/)。将原始 GitHub 链接中的域名替换为 `https://gh-proxy.com/`，例如：
- 原始链接：`https://raw.githubusercontent.com/username/repo/main/file.txt`
- 代理链接：`https://gh-proxy.com/https://raw.githubusercontent.com/username/repo/main/file.txt`

### 克隆代码仓库

通过代理克隆 GitHub 代码仓库：
```bash
git clone https://gh-proxy.com/https://github.com/huggingface/transformers.git
git clone https://gh-proxy.com/https://github.com/volcengine/verl.git
git clone https://gh-proxy.com/https://github.com/wangshuai09/vllm.git
git clone https://gh-proxy.com/https://gitee.com/ascend/MindSpeed.git
git clone https://gh-proxy.com/https://github.com/NVIDIA/Megatron-LM.git
git clone https://gh-proxy.com/https://github.com/huggingface/trl.git
git clone https://gh-proxy.com/https://github.com/hkust-nlp/simpleRL-reason.git
git clone https://gh-proxy.com/https://github.com/as12138/verl.git verl-npu
```



## 模型-数据集下载

参考网站 https://hf-mirror.com/ 说明

### 安装依赖

```bash
pip install -U huggingface_hub
```

### 配置环境变量

在运行脚本前，需要配置以下环境变量以指定国内镜像源：
```bash
export HF_ENDPOINT="https://hf-mirror.com"
export HF_HUB_ENABLE_HF_TRANSFER=0
```
注意：如果无法访问 `https://hf-mirror.com`，请检查链接的合法性或网络连接。如果问题持续存在，可以尝试更换其他可用的镜像源。

### 下载模型权重

运行脚本后，将按以下路径下载指定的模型权重：
```bash
huggingface-cli download Qwen/Qwen2.5-0.5B --local-dir /root/llmtuner/hfhub/models/Qwen/Qwen2.5-0.5B
huggingface-cli download Qwen/Qwen2.5-0.5B-Instruct --local-dir /root/llmtuner/hfhub/models/Qwen/Qwen2.5-0.5B-Instruct
```

### 下载数据集

```bash
huggingface-cli download  --repo-type dataset openai/gsm8k  --local-dir /root/llmtuner/hfhub/datasets/openai/gsm8k
huggingface-cli download  --repo-type dataset BytedTsinghua-SIA/DAPO-Math-17k  --local-dir /root/llmtuner/hfhub/datasets/BytedTsinghua-SIA/DAPO-Math-17k
```

### Shell 脚本

以下是完整的脚本内容，您可以将其保存为 `download_script.sh` 并运行：
```bash
#!/bin/bash
# 需要配置国内镜像源
export HF_ENDPOINT="https://hf-mirror.com"
export HF_HUB_ENABLE_HF_TRANSFER=0

# 模型权重
## Qwen2.5
huggingface-cli download Qwen/Qwen2.5-0.5B --local-dir /root/llmtuner/hfhub/models/Qwen/Qwen2.5-0.5B
huggingface-cli download Qwen/Qwen2.5-0.5B-Instruct --local-dir /root/llmtuner/hfhub/models/Qwen/Qwen2.5-0.5B-Instruct

## 数据集
huggingface-cli download  --repo-type dataset openai/gsm8k  --local-dir /root/llmtuner/hfhub/datasets/openai/gsm8k
huggingface-cli download  --repo-type dataset BytedTsinghua-SIA/DAPO-Math-17k  --local-dir /root/llmtuner/hfhub/datasets/BytedTsinghua-SIA/DAPO-Math-17k
```



## 测试集群通信

创建文件名 allreduce_demo.py

```Python
import torch
import torch_npu
from torch_npu.contrib import transfer_to_npu
import torch.distributed as dist
import os

def main():
    # 初始化分布式环境
    local_rank = int(os.environ["LOCAL_RANK"])
    world_size = int(os.environ["WORLD_SIZE"])
    rank = int(os.environ["RANK"])

    # 设置NPU设备
    torch.npu.set_device(local_rank)
    # 获取当前设备
    device = torch.device(f"npu:{torch.npu.current_device()}")

    # 初始化进程组
    dist.init_process_group(backend="hccl")

    # 创建tensor并移到当前NPU设备
    tensor = torch.ones(2, 2, dtype=torch.float16, device=device) * (rank + 1)

    print(f'Rank {rank} 的初始tensor:\n{tensor}')
    print(f'Tensor dtype: {tensor.dtype}')
    print(f'Tensor device: {tensor.device}')

    # 执行all-reduce操作
    dist.all_reduce(tensor, op=dist.ReduceOp.SUM)

    print(f'Rank {rank} 的all-reduce结果:\n{tensor}')

    # 清理
    dist.destroy_process_group()

if __name__ == "__main__":
    main()
```

创建运行文件 run.sh

```Shell
#!/bin/bash

# 设置NPU可见设备
export ASCEND_VISIBLE_DEVICES=0,1,2,3,4,5,6,7

# 使用torchrun启动分布式训练
torchrun \
    --nproc_per_node=8 \
    --nnodes=1 \
    --node_rank=0 \
    --master_addr="localhost" \
    --master_port=29500 \
    allreduce_demo.py
```

执行 run.sh

```Shell
bash run.sh
```



##   常用集群任务命令

### 运行后台任务

使用 `nohup` 命令在后台运行脚本，并将输出重定向到日志文件：
```bash
nohup sh download_hf_weights.sh > output2.log 2>&1 &
```

### 查看后台进程

查看后台运行的进程：
```bash
ps aux | grep hugg
```

### Kill 命令

```Shell
ps aux | grep python | awk '{print $2}' | xargs kill -9
```

### 清理Torch 扩展缓存

清理 PyTorch 扩展的缓存文件：
```bash
rm -rf /root/.cache/torch_extensions/py310_cpu
```



## Wandb 同步本地 wandb 日志

如果你想将本地的 log 文件同步上传到 Weights & Biases (W&B)，可以使用 `wandb sync` 命令。以下是详细的方法：

------

### 1：自动同步

如果你是使用 `wandb.init()` 进行实验跟踪，并且在线运行，W&B 会 自动上传 训练日志，不需要额外操作。

------

### 2：手动同步本地日志

如果你在 离线模式 (`WANDB_MODE=offline`) 运行了实验，W&B 会将日志保存在本地。你可以手动上传这些日志。

#### 步骤 1：找到本地日志

W&B 默认将本地的日志存储在：

```bash
~/.wandb/
```

或者当前项目目录的 `wandb` 文件夹下：

```bash
wandb/run-<RUN_ID>/  # 每个实验的日志都在单独的文件夹
```

#### 步骤 2：手动同步

使用以下命令同步本地存储的日志：

```bash
wandb sync wandb/
```

或同步特定日志：

```bash
wandb sync wandb/run-<RUN_ID>/
```

#### 示例

如果你想同步所有未上传的日志：

```bash
wandb sync --sync-all
```

------

### 3：强制同步

如果 `wandb sync` 没有效果，可以尝试：

```bash
wandb sync --include-offline
```

或者清理无效的本地缓存后再同步：

```bash
wandb sync --clean
wandb sync
```

------

### 4：上传到特定项目

如果你想把日志上传到指定的 W&B 项目，可以在运行时设置：

```bash
WANDB_PROJECT="your_project_name" wandb sync wandb/
```

------

### 解决常见问题

### 1️⃣ `wandb sync` 没有效果？

可能原因：

- W&B 服务器无法访问（检查网络）
- 本地日志文件损坏
- 已经同步过了（可以用 `wandb sync --clean` 先清理）



## Wandb 同步本地 tensorbaord 日志

如果你有 本地 TensorBoard 日志（如 `.tfevents` 文件）并希望同步到 Weights & Biases (W&B)，可以按照以下步骤操作：

------

### 1：使用 `wandb sync` 命令

W&B 提供了 wandb sync 命令，可以直接同步本地 TensorBoard 文件：

```bash
wandb sync --sync-tensorboard <tensorboard_log_dir>
```

- `<tensorboard_log_dir>` 是你的 TensorBoard 日志目录，例如 `logs/`。这会自动解析 TensorBoard 的 `.tfevents` 文件，并将数据上传到 W&B。

### 2：使用 Python 代码直接同步

如果你在 Python 代码中运行 TensorBoard，可以手动集成 W&B：

#### 步骤 1：初始化 W&B

在你的训练脚本中：

```python
import wandb
wandb.init(project="your_project_name")
```

#### 步骤 2：让 W&B 监测 TensorBoard 日志

你可以让 W&B 监听 TensorBoard 目录：

```python
wandb.tensorboard.patch(root_logdir="logs/")
```

或者直接：

```python
wandb.init(sync_tensorboard=True)
```

#### 示例

```python
import wandb
import tensorflow as tf

# 初始化 wandb
wandb.init(project="my_project", sync_tensorboard=True)

# 定义 TensorBoard 目录
tensorboard_logdir = "logs/"

# 创建 TensorBoard 记录器
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tensorboard_logdir)

# 训练模型
model.fit(x_train, y_train, epochs=10, callbacks=[tensorboard_callback])
```

这样，TensorBoard 生成的 `.tfevents` 日志会 自动同步 到 W&B。

|#                            | 适用场景                          | 命令                                           |
| ------------------------------- | --------------------------------- | ---------------------------------------------- |
| `wandb sync --tensorboard`  | 现有 TensorBoard 日志 (.tfevents) | `wandb sync --tensorboard logs/`               |
| `wandb.tensorboard.patch()` | 在训练过程中同步                  | `wandb.tensorboard.patch(root_logdir="logs/")` |
