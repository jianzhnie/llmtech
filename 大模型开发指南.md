# Ascend å¼€å‘ç¯å¢ƒé…ç½®ä¸æ“ä½œæŒ‡å—

### CANN ç¯å¢ƒé…ç½®

åŠ è½½ CANN ç¯å¢ƒå˜é‡ï¼Œè·¯å¾„éœ€æ ¹æ®å®é™…å®‰è£…ä½ç½®è¿›è¡Œè°ƒæ•´ï¼š
```bash
install_path=/usr/local/Ascend
source $install_path/ascend-toolkit/set_env.sh
source $install_path/nnal/atb/set_env.sh
```

### æ£€æŸ¥ NPU çŠ¶æ€

è¿è¡Œä»¥ä¸‹å‘½ä»¤ä»¥æ£€æŸ¥ NPU çŠ¶æ€ï¼š
```bash
npu-smi info
```

###  å®‰è£… torch & torch-npu

```bash
pip install numpy==1.26.0
pip install torch==2.5.1 && pip install torch-npu==2.5.1rc1
```

### PIP ä¸‹è½½æº

```bash
# tsinghua æº
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple --trusted-host pypi.tuna.tsinghua.edu.cn numpy==1.26.0

# aliyun æº
pip install -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com numpy==1.26.0
```

### æŒ‚è½½æ•°æ®å­˜å‚¨

æŒ‚è½½åˆ†å¸ƒå¼æŒä¹…åŒ–å­˜å‚¨ï¼ˆDPCï¼‰ï¼š
```bash
mount -t dpc /llmtuner llmtuner
```

### ä¿®æ”¹æ–‡ä»¶æƒé™

ä¿®æ”¹ Miniconda æ–‡ä»¶å¤¹çš„æƒé™ï¼š
```bash
chown -R HwHiAiUser:users miniconda3/
chmod -R 755 miniconda3/
```

### ç™»å½• wandb

ç™»å½• wandbï¼Œç”¨äºå®éªŒè·Ÿè¸ªä¸å¯è§†åŒ–ï¼š
```bash
wandb login 8ad58a961091cd50e8ed0b00d9060e502209a2b5
```

### Conda å…‹éš†  Env

åœ¨ Conda ä¸­ï¼Œ**ç¯å¢ƒä¸èƒ½ç›´æ¥é‡å‘½å**ï¼Œä½†ä½ å¯ä»¥é€šè¿‡**å…‹éš†+åˆ é™¤**çš„æ–¹å¼è¾¾åˆ°ç›¸åŒæ•ˆæœã€‚ä»¥ä¸‹æ˜¯æ­¥éª¤ï¼š

å‡è®¾ä½ æƒ³æŠŠç¯å¢ƒ `old_env_name` é‡å‘½åä¸º `new_env_name`ã€‚

#### æ­¥éª¤ 1ï¼šå…‹éš†ç¯å¢ƒ

```bash
conda create --name new_env_name --clone old_env_name
```

##### **æ˜¾å¼æŒ‡å®šç›®æ ‡è·¯å¾„**

```
conda create --prefix /root/llmtuner/miniconda3/envs/rlhf --clone /root/llm_workspace/miniconda3/envs/openRLHF
```

#### æ­¥éª¤ 2ï¼šç¡®è®¤æ–°ç¯å¢ƒåˆ›å»ºæˆåŠŸ

```bash
conda info --envs
```

#### æ­¥éª¤ 3ï¼šåˆ é™¤æ—§ç¯å¢ƒï¼ˆå¦‚æœç¡®è®¤æ— è¯¯ï¼‰

```bash
conda remove --name old_env_name --all
```

------

#### ğŸ“ æ³¨æ„äº‹é¡¹ï¼š

- å…‹éš†ç¯å¢ƒä¼šå¤åˆ¶æ‰€æœ‰åŒ…å’Œä¾èµ–ï¼Œè¿‡ç¨‹å¯èƒ½ç¨æ…¢ã€‚
- åˆ é™¤æ—§ç¯å¢ƒå‰è¯·ç¡®ä¿ `new_env_name` å¯æ­£å¸¸ä½¿ç”¨ã€‚

## ä»£ç ä¸èµ„æºè·å–

### ä½¿ç”¨ GitHub ä»£ç†

ä¸ºäº†åŠ é€Ÿ GitHub æ–‡ä»¶çš„ä¸‹è½½ï¼Œå¯ä»¥ä½¿ç”¨ [GitHub æ–‡ä»¶åŠ é€Ÿä»£ç†](https://gh-proxy.com/)ã€‚å°†åŸå§‹ GitHub é“¾æ¥ä¸­çš„åŸŸåæ›¿æ¢ä¸º `https://gh-proxy.com/`ï¼Œä¾‹å¦‚ï¼š
- åŸå§‹é“¾æ¥ï¼š`https://raw.githubusercontent.com/username/repo/main/file.txt`
- ä»£ç†é“¾æ¥ï¼š`https://gh-proxy.com/https://raw.githubusercontent.com/username/repo/main/file.txt`

### å…‹éš†ä»£ç ä»“åº“

é€šè¿‡ä»£ç†å…‹éš† GitHub ä»£ç ä»“åº“ï¼š
```bash
git clone https://gh-proxy.com/https://github.com/huggingface/transformers.git
git clone https://gh-proxy.com/https://github.com/volcengine/verl.git
git clone https://gh-proxy.com/https://github.com/wangshuai09/vllm.git
git clone https://gh-proxy.com/https://gitee.com/ascend/MindSpeed.git
git clone https://gh-proxy.com/https://github.com/NVIDIA/Megatron-LM.git
git clone https://gh-proxy.com/https://github.com/huggingface/trl.git
git clone https://gh-proxy.com/https://github.com/hkust-nlp/simpleRL-reason.git
git clone https://gh-proxy.com/https://github.com/as12138/verl.git verl-npu
```



## Git ä»“åº“åˆå¹¶å¤–éƒ¨PR

å°† Git ä»“åº“çš„ Pull Request (PR) åˆå¹¶åˆ°ä¸»ä»“åº“çš„æ­¥éª¤å¦‚ä¸‹ï¼Œå…·ä½“æ“ä½œå¯èƒ½å› ä»£ç æ‰˜ç®¡å¹³å°ï¼ˆå¦‚ GitHubã€GitLabã€Bitbucket ç­‰ï¼‰ç•¥æœ‰ä¸åŒï¼Œä½†æ ¸å¿ƒæµç¨‹ä¸€è‡´ã€‚ä»¥ä¸‹æ˜¯é€šç”¨æ­¥éª¤ï¼š

---

### **1. ç¡®ä¿ä½ æœ‰åˆå¹¶æƒé™**

- ä½ éœ€è¦åœ¨ä¸»ä»“åº“æœ‰ **å†™å…¥æƒé™** æˆ– **åˆå¹¶ PR çš„æƒé™**ï¼ˆå¦‚æœæ˜¯å¼€æºé¡¹ç›®ï¼Œå¯èƒ½éœ€è¦ç»´æŠ¤è€…å®¡æ ¸ï¼‰ã€‚

---

### **2. åœ¨ä»£ç æ‰˜ç®¡å¹³å°ä¸Šæ“ä½œï¼ˆä»¥ GitHub ä¸ºä¾‹ï¼‰**
#### **æ–¹æ³•ä¸€ï¼šé€šè¿‡ Web ç•Œé¢åˆå¹¶**
1. **è¿›å…¥ PR é¡µé¢**
   åœ¨ä»“åº“çš„ `Pull Requests` æ ‡ç­¾é¡µæ‰¾åˆ°ç›®æ ‡ PRã€‚

2. **æ£€æŸ¥ PR çŠ¶æ€**
   - ç¡®ä¿ CI æ£€æŸ¥é€šè¿‡ï¼ˆå¦‚ GitHub Actionsã€Travis CI ç­‰ï¼‰ã€‚
   - ç¡®ä¿æ²¡æœ‰å†²çªï¼ˆè‹¥æœ‰å†²çªéœ€å…ˆè§£å†³ï¼‰ã€‚

3. **é€‰æ‹©åˆå¹¶æ–¹å¼**
   GitHub æä¾›ä¸‰ç§åˆå¹¶é€‰é¡¹ï¼ˆç‚¹å‡» `Merge pull request` ä¸‹æ‹‰èœå•ï¼‰ï¼š
   - **Create a merge commit**ï¼šç”Ÿæˆä¸€ä¸ªåˆå¹¶æäº¤ï¼ˆä¿ç•™å®Œæ•´å†å²ï¼Œæ¨èï¼‰ã€‚
   - **Squash and merge**ï¼šå°†å¤šä¸ªæäº¤å‹ç¼©æˆä¸€ä¸ªï¼ˆç®€åŒ–å†å²ï¼‰ã€‚
   - **Rebase and merge**ï¼šçº¿æ€§åˆå¹¶ï¼ˆä¸æ¨èç”¨äºå¤šäººåä½œçš„ä¸»åˆ†æ”¯ï¼‰ã€‚

4. **ç¡®è®¤åˆå¹¶**
   ç‚¹å‡» `Confirm merge`ï¼ŒPR ä¼šè¢«åˆå¹¶åˆ°ç›®æ ‡åˆ†æ”¯ï¼ˆé€šå¸¸æ˜¯ `main` æˆ– `master`ï¼‰ã€‚

5. **åˆ é™¤åˆ†æ”¯ï¼ˆå¯é€‰ï¼‰**
   åˆå¹¶åå¯ä»¥ç‚¹å‡» `Delete branch` æ¸…ç†æ¥æºåˆ†æ”¯ã€‚

---

#### **æ–¹æ³•äºŒï¼šé€šè¿‡å‘½ä»¤è¡Œåˆå¹¶ï¼ˆé€‚åˆéœ€è¦æœ¬åœ°æ£€æŸ¥çš„æƒ…å†µï¼‰**
1. **å°†ä¸»ä»“åº“å’Œ PR åˆ†æ”¯æ‹‰åˆ°æœ¬åœ°**
   ```bash
   git clone <ä¸»ä»“åº“URL>
   cd <ä»“åº“ç›®å½•>
   git remote add <è´¡çŒ®è€…å> <PRæ¥æºä»“åº“URL>  # å¦‚æœPRæ¥è‡ªå¤–éƒ¨ä»“åº“
   git fetch <è´¡çŒ®è€…å> <PRåˆ†æ”¯å>
   ```

2. **åˆ‡æ¢åˆ°ç›®æ ‡åˆ†æ”¯å¹¶åˆå¹¶**
   ```bash
   git checkout main       # åˆ‡æ¢åˆ°ä¸»åˆ†æ”¯
   git merge <PRåˆ†æ”¯å>    # åˆå¹¶PRåˆ†æ”¯
   ```

3. **è§£å†³å†²çªï¼ˆå¦‚æœæœ‰ï¼‰**
   - æ‰‹åŠ¨è§£å†³å†²çªåæäº¤ï¼š
     ```bash
     git add .
     git commit -m "Merge PR #<PRç¼–å·>: <æè¿°>"
     ```

4. **æ¨é€åˆ°ä¸»ä»“åº“**
   ```bash
   git push origin main
   ```

---

### **3. éªŒè¯åˆå¹¶**
- åœ¨ä»“åº“çš„ `Commits` æˆ– `Network` å›¾è¡¨ä¸­ç¡®è®¤åˆå¹¶ç»“æœã€‚
- è¿è¡Œæµ‹è¯•ç¡®ä¿åŠŸèƒ½æ­£å¸¸ã€‚

---

### **æ³¨æ„äº‹é¡¹**
1. **æƒé™é—®é¢˜**
   - å¦‚æœæ— æƒåˆå¹¶ï¼Œéœ€è¦è”ç³»ä»“åº“ç®¡ç†å‘˜ã€‚
2. **ä¿æŠ¤åˆ†æ”¯è§„åˆ™**
   - ä¸»åˆ†æ”¯å¯èƒ½å—ä¿æŠ¤ï¼ˆéœ€é€šè¿‡ CI æˆ–æŒ‡å®šå®¡æ ¸äººï¼‰ã€‚
3. **ä»£ç å®¡æŸ¥**
   - åˆå¹¶å‰å»ºè®®é€šè¿‡ `Review` åŠŸèƒ½è¿›è¡Œä»£ç å®¡æŸ¥ã€‚
4. **è·¨ä»“åº“ PR**
   - å¦‚æœ PR æ¥è‡ªå¤–éƒ¨ä»“åº“ï¼ˆForkï¼‰ï¼Œéœ€å…ˆæ‹‰å–åˆ°æœ¬åœ°æ£€æŸ¥ã€‚

---

### **å…¶ä»–å¹³å°å·®å¼‚**
- **GitLab**ï¼šæ“ä½œç±»ä¼¼ï¼Œç§°ä¸º `Merge Request (MR)`ï¼Œåˆå¹¶æŒ‰é’®åœ¨ MR é¡µé¢ã€‚
- **Bitbucket**ï¼šæµç¨‹ç›¸è¿‘ï¼Œåˆå¹¶é€‰é¡¹åœ¨ PR é¡µé¢çš„ `Merge` æŒ‰é’®ä¸­ã€‚

é€šè¿‡ä»¥ä¸Šæ­¥éª¤ï¼Œä½ å¯ä»¥å®‰å…¨åœ°å°† PR åˆå¹¶åˆ°ä¸»ä»“åº“ã€‚



## æ¨¡å‹-æ•°æ®é›†ä¸‹è½½

å‚è€ƒç½‘ç«™ https://hf-mirror.com/ è¯´æ˜

### å®‰è£…ä¾èµ–

```bash
pip install -U huggingface_hub
```

### é…ç½®ç¯å¢ƒå˜é‡

åœ¨è¿è¡Œè„šæœ¬å‰ï¼Œéœ€è¦é…ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ä»¥æŒ‡å®šå›½å†…é•œåƒæºï¼š
```bash
export HF_ENDPOINT="https://hf-mirror.com"
export HF_HUB_ENABLE_HF_TRANSFER=0
```
æ³¨æ„ï¼šå¦‚æœæ— æ³•è®¿é—® `https://hf-mirror.com`ï¼Œè¯·æ£€æŸ¥é“¾æ¥çš„åˆæ³•æ€§æˆ–ç½‘ç»œè¿æ¥ã€‚å¦‚æœé—®é¢˜æŒç»­å­˜åœ¨ï¼Œå¯ä»¥å°è¯•æ›´æ¢å…¶ä»–å¯ç”¨çš„é•œåƒæºã€‚

### ä¸‹è½½æ¨¡å‹æƒé‡

è¿è¡Œè„šæœ¬åï¼Œå°†æŒ‰ä»¥ä¸‹è·¯å¾„ä¸‹è½½æŒ‡å®šçš„æ¨¡å‹æƒé‡ï¼š
```bash
huggingface-cli download Qwen/Qwen2.5-0.5B --local-dir /root/llmtuner/hfhub/models/Qwen/Qwen2.5-0.5B
huggingface-cli download Qwen/Qwen2.5-0.5B-Instruct --local-dir /root/llmtuner/hfhub/models/Qwen/Qwen2.5-0.5B-Instruct
```

### ä¸‹è½½æ•°æ®é›†

```bash
huggingface-cli download  --repo-type dataset openai/gsm8k  --local-dir /root/llmtuner/hfhub/datasets/openai/gsm8k
huggingface-cli download  --repo-type dataset BytedTsinghua-SIA/DAPO-Math-17k  --local-dir /root/llmtuner/hfhub/datasets/BytedTsinghua-SIA/DAPO-Math-17k
```

### Shell è„šæœ¬

ä»¥ä¸‹æ˜¯å®Œæ•´çš„è„šæœ¬å†…å®¹ï¼Œæ‚¨å¯ä»¥å°†å…¶ä¿å­˜ä¸º `download_script.sh` å¹¶è¿è¡Œï¼š
```bash
#!/bin/bash
# éœ€è¦é…ç½®å›½å†…é•œåƒæº
export HF_ENDPOINT="https://hf-mirror.com"
export HF_HUB_ENABLE_HF_TRANSFER=0

# æ¨¡å‹æƒé‡
## Qwen2.5
huggingface-cli download Qwen/Qwen2.5-0.5B --local-dir /root/llmtuner/hfhub/models/Qwen/Qwen2.5-0.5B
huggingface-cli download Qwen/Qwen2.5-0.5B-Instruct --local-dir /root/llmtuner/hfhub/models/Qwen/Qwen2.5-0.5B-Instruct

## æ•°æ®é›†
huggingface-cli download  --repo-type dataset openai/gsm8k  --local-dir /root/llmtuner/hfhub/datasets/openai/gsm8k
huggingface-cli download  --repo-type dataset BytedTsinghua-SIA/DAPO-Math-17k  --local-dir /root/llmtuner/hfhub/datasets/BytedTsinghua-SIA/DAPO-Math-17k
```



## æµ‹è¯•é›†ç¾¤é€šä¿¡

åˆ›å»ºæ–‡ä»¶å allreduce_demo.py

```Python
import torch
import torch_npu
from torch_npu.contrib import transfer_to_npu
import torch.distributed as dist
import os

def main():
    # åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ
    local_rank = int(os.environ["LOCAL_RANK"])
    world_size = int(os.environ["WORLD_SIZE"])
    rank = int(os.environ["RANK"])

    # è®¾ç½®NPUè®¾å¤‡
    torch.npu.set_device(local_rank)
    # è·å–å½“å‰è®¾å¤‡
    device = torch.device(f"npu:{torch.npu.current_device()}")

    # åˆå§‹åŒ–è¿›ç¨‹ç»„
    dist.init_process_group(backend="hccl")

    # åˆ›å»ºtensorå¹¶ç§»åˆ°å½“å‰NPUè®¾å¤‡
    tensor = torch.ones(2, 2, dtype=torch.float16, device=device) * (rank + 1)

    print(f'Rank {rank} çš„åˆå§‹tensor:\n{tensor}')
    print(f'Tensor dtype: {tensor.dtype}')
    print(f'Tensor device: {tensor.device}')

    # æ‰§è¡Œall-reduceæ“ä½œ
    dist.all_reduce(tensor, op=dist.ReduceOp.SUM)

    print(f'Rank {rank} çš„all-reduceç»“æœ:\n{tensor}')

    # æ¸…ç†
    dist.destroy_process_group()

if __name__ == "__main__":
    main()
```

åˆ›å»ºè¿è¡Œæ–‡ä»¶ run.sh

```Shell
#!/bin/bash

# è®¾ç½®NPUå¯è§è®¾å¤‡
export ASCEND_VISIBLE_DEVICES=0,1,2,3,4,5,6,7

# ä½¿ç”¨torchrunå¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒ
torchrun \
    --nproc_per_node=8 \
    --nnodes=1 \
    --node_rank=0 \
    --master_addr="localhost" \
    --master_port=29500 \
    allreduce_demo.py
```

æ‰§è¡Œ run.sh

```Shell
bash run.sh
```



##   å¸¸ç”¨é›†ç¾¤ä»»åŠ¡å‘½ä»¤

### è¿è¡Œåå°ä»»åŠ¡

ä½¿ç”¨ `nohup` å‘½ä»¤åœ¨åå°è¿è¡Œè„šæœ¬ï¼Œå¹¶å°†è¾“å‡ºé‡å®šå‘åˆ°æ—¥å¿—æ–‡ä»¶ï¼š
```bash
nohup sh download_hf_weights.sh > output2.log 2>&1 &
```

### æŸ¥çœ‹åå°è¿›ç¨‹

æŸ¥çœ‹åå°è¿è¡Œçš„è¿›ç¨‹ï¼š
```bash
ps aux | grep hugg
```

### Kill å‘½ä»¤

```Shell
ps aux | grep python | awk '{print $2}' | xargs kill -9
```

### æ¸…ç†Torch æ‰©å±•ç¼“å­˜

æ¸…ç† PyTorch æ‰©å±•çš„ç¼“å­˜æ–‡ä»¶ï¼š
```bash
rm -rf /root/.cache/torch_extensions/py310_cpu
```



## Wandb åŒæ­¥æœ¬åœ° wandb æ—¥å¿—

å¦‚æœä½ æƒ³å°†æœ¬åœ°çš„ log æ–‡ä»¶åŒæ­¥ä¸Šä¼ åˆ° Weights & Biases (W&B)ï¼Œå¯ä»¥ä½¿ç”¨ `wandb sync` å‘½ä»¤ã€‚ä»¥ä¸‹æ˜¯è¯¦ç»†çš„æ–¹æ³•ï¼š

------

### 1ï¼šè‡ªåŠ¨åŒæ­¥

å¦‚æœä½ æ˜¯ä½¿ç”¨ `wandb.init()` è¿›è¡Œå®éªŒè·Ÿè¸ªï¼Œå¹¶ä¸”åœ¨çº¿è¿è¡Œï¼ŒW&B ä¼š è‡ªåŠ¨ä¸Šä¼  è®­ç»ƒæ—¥å¿—ï¼Œä¸éœ€è¦é¢å¤–æ“ä½œã€‚

### 2ï¼šæ‰‹åŠ¨åŒæ­¥æœ¬åœ°æ—¥å¿—

å¦‚æœä½ åœ¨ ç¦»çº¿æ¨¡å¼ (`WANDB_MODE=offline`) è¿è¡Œäº†å®éªŒï¼ŒW&B ä¼šå°†æ—¥å¿—ä¿å­˜åœ¨æœ¬åœ°ã€‚ä½ å¯ä»¥æ‰‹åŠ¨ä¸Šä¼ è¿™äº›æ—¥å¿—ã€‚

#### æ­¥éª¤ 1ï¼šæ‰¾åˆ°æœ¬åœ°æ—¥å¿—

W&B é»˜è®¤å°†æœ¬åœ°çš„æ—¥å¿—å­˜å‚¨åœ¨ï¼š

```bash
~/.wandb/
```

æˆ–è€…å½“å‰é¡¹ç›®ç›®å½•çš„ `wandb` æ–‡ä»¶å¤¹ä¸‹ï¼š

```bash
wandb/run-<RUN_ID>/  # æ¯ä¸ªå®éªŒçš„æ—¥å¿—éƒ½åœ¨å•ç‹¬çš„æ–‡ä»¶å¤¹
```

#### æ­¥éª¤ 2ï¼šæ‰‹åŠ¨åŒæ­¥

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤åŒæ­¥æœ¬åœ°å­˜å‚¨çš„æ—¥å¿—ï¼š

```bash
wandb sync wandb/
```

æˆ–åŒæ­¥ç‰¹å®šæ—¥å¿—ï¼š

```bash
wandb sync wandb/run-<RUN_ID>/
```

#### ç¤ºä¾‹

å¦‚æœä½ æƒ³åŒæ­¥æ‰€æœ‰æœªä¸Šä¼ çš„æ—¥å¿—ï¼š

```bash
wandb sync --sync-all
```

------

### 3ï¼šå¼ºåˆ¶åŒæ­¥

å¦‚æœ `wandb sync` æ²¡æœ‰æ•ˆæœï¼Œå¯ä»¥å°è¯•ï¼š

```bash
wandb sync --include-offline
```

æˆ–è€…æ¸…ç†æ— æ•ˆçš„æœ¬åœ°ç¼“å­˜åå†åŒæ­¥ï¼š

```bash
wandb sync --clean
wandb sync
```

------

### 4ï¼šä¸Šä¼ åˆ°ç‰¹å®šé¡¹ç›®

å¦‚æœä½ æƒ³æŠŠæ—¥å¿—ä¸Šä¼ åˆ°æŒ‡å®šçš„ W&B é¡¹ç›®ï¼Œå¯ä»¥åœ¨è¿è¡Œæ—¶è®¾ç½®ï¼š

```bash
WANDB_PROJECT="your_project_name" wandb sync wandb/
```

------

### è§£å†³å¸¸è§é—®é¢˜

### 1ï¸âƒ£ `wandb sync` æ²¡æœ‰æ•ˆæœï¼Ÿ

å¯èƒ½åŸå› ï¼š

- W&B æœåŠ¡å™¨æ— æ³•è®¿é—®ï¼ˆæ£€æŸ¥ç½‘ç»œï¼‰
- æœ¬åœ°æ—¥å¿—æ–‡ä»¶æŸå
- å·²ç»åŒæ­¥è¿‡äº†ï¼ˆå¯ä»¥ç”¨ `wandb sync --clean` å…ˆæ¸…ç†ï¼‰

## Wandb åŒæ­¥æœ¬åœ° tensorbaord æ—¥å¿—

å¦‚æœä½ æœ‰ æœ¬åœ° TensorBoard æ—¥å¿—ï¼ˆå¦‚ `.tfevents` æ–‡ä»¶ï¼‰å¹¶å¸Œæœ›åŒæ­¥åˆ° Weights & Biases (W&B)ï¼Œå¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š

------

### 1ï¼šä½¿ç”¨ `wandb sync` å‘½ä»¤

W&B æä¾›äº† wandb sync å‘½ä»¤ï¼Œå¯ä»¥ç›´æ¥åŒæ­¥æœ¬åœ° TensorBoard æ–‡ä»¶ï¼š

```bash
wandb sync --sync-tensorboard <tensorboard_log_dir>
```

- `<tensorboard_log_dir>` æ˜¯ä½ çš„ TensorBoard æ—¥å¿—ç›®å½•ï¼Œä¾‹å¦‚ `logs/`ã€‚è¿™ä¼šè‡ªåŠ¨è§£æ TensorBoard çš„ `.tfevents` æ–‡ä»¶ï¼Œå¹¶å°†æ•°æ®ä¸Šä¼ åˆ° W&Bã€‚

### 2ï¼šä½¿ç”¨ Python ä»£ç ç›´æ¥åŒæ­¥

å¦‚æœä½ åœ¨ Python ä»£ç ä¸­è¿è¡Œ TensorBoardï¼Œå¯ä»¥æ‰‹åŠ¨é›†æˆ W&Bï¼š

#### æ­¥éª¤ 1ï¼šåˆå§‹åŒ– W&B

åœ¨ä½ çš„è®­ç»ƒè„šæœ¬ä¸­ï¼š

```python
import wandb
wandb.init(project="your_project_name")
```

#### æ­¥éª¤ 2ï¼šè®© W&B ç›‘æµ‹ TensorBoard æ—¥å¿—

ä½ å¯ä»¥è®© W&B ç›‘å¬ TensorBoard ç›®å½•ï¼š

```python
wandb.tensorboard.patch(root_logdir="logs/")
```

æˆ–è€…ç›´æ¥ï¼š

```python
wandb.init(sync_tensorboard=True)
```

#### ç¤ºä¾‹

```python
import wandb
import tensorflow as tf

# åˆå§‹åŒ– wandb
wandb.init(project="my_project", sync_tensorboard=True)

# å®šä¹‰ TensorBoard ç›®å½•
tensorboard_logdir = "logs/"

# åˆ›å»º TensorBoard è®°å½•å™¨
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tensorboard_logdir)

# è®­ç»ƒæ¨¡å‹
model.fit(x_train, y_train, epochs=10, callbacks=[tensorboard_callback])
```

è¿™æ ·ï¼ŒTensorBoard ç”Ÿæˆçš„ `.tfevents` æ—¥å¿—ä¼š è‡ªåŠ¨åŒæ­¥ åˆ° W&Bã€‚

|#                            | é€‚ç”¨åœºæ™¯                          | å‘½ä»¤                                           |
| ------------------------------- | --------------------------------- | ---------------------------------------------- |
| `wandb sync --tensorboard`  | ç°æœ‰ TensorBoard æ—¥å¿— (.tfevents) | `wandb sync --tensorboard logs/`               |
| `wandb.tensorboard.patch()` | åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŒæ­¥                  | `wandb.tensorboard.patch(root_logdir="logs/")` |
