# Ascend 开发环境配置与操作指南

### CANN 环境配置

加载 CANN 环境变量，路径需根据实际安装位置进行调整：
```bash
install_path=/usr/local/Ascend
source $install_path/ascend-toolkit/set_env.sh
source $install_path/nnal/atb/set_env.sh
```

### 检查 NPU 状态

运行以下命令以检查 NPU 状态：
```bash
npu-smi info
```

###  安装 torch & torch-npu

```bash
pip install numpy==1.26.0
pip install torch==2.5.1 && pip install torch-npu==2.5.1rc1
```

### PIP 下载源

```bash
# tsinghua 源
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple --trusted-host pypi.tuna.tsinghua.edu.cn numpy==1.26.0

# aliyun 源
pip install -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com numpy==1.26.0
```

### 挂载数据存储

挂载分布式持久化存储（DPC）：
```bash
mount -t dpc /llmtuner llmtuner
```

### 修改文件权限

修改 Miniconda 文件夹的权限：
```bash
chown -R HwHiAiUser:users miniconda3/
chmod -R 755 miniconda3/
```

### 登录 wandb

登录 wandb，用于实验跟踪与可视化：
```bash
wandb login 8ad58a961091cd50e8ed0b00d9060e502209a2b5
```

### Conda 克隆  Env

在 Conda 中，**环境不能直接重命名**，但你可以通过**克隆+删除**的方式达到相同效果。以下是步骤：

假设你想把环境 `old_env_name` 重命名为 `new_env_name`。

#### 步骤 1：克隆环境

```bash
conda create --name new_env_name --clone old_env_name
```

##### **显式指定目标路径**

```
conda create --prefix /root/llmtuner/miniconda3/envs/rlhf --clone /root/llm_workspace/miniconda3/envs/openRLHF
```

#### 步骤 2：确认新环境创建成功

```bash
conda info --envs
```

#### 步骤 3：删除旧环境（如果确认无误）

```bash
conda remove --name old_env_name --all
```

------

#### 📝 注意事项：

- 克隆环境会复制所有包和依赖，过程可能稍慢。
- 删除旧环境前请确保 `new_env_name` 可正常使用。

## 代码与资源获取

### 使用 GitHub 代理

为了加速 GitHub 文件的下载，可以使用 [GitHub 文件加速代理](https://gh-proxy.com/)。将原始 GitHub 链接中的域名替换为 `https://gh-proxy.com/`，例如：
- 原始链接：`https://raw.githubusercontent.com/username/repo/main/file.txt`
- 代理链接：`https://gh-proxy.com/https://raw.githubusercontent.com/username/repo/main/file.txt`

### 克隆代码仓库

通过代理克隆 GitHub 代码仓库：
```bash
git clone https://gh-proxy.com/https://github.com/huggingface/transformers.git
git clone https://gh-proxy.com/https://github.com/volcengine/verl.git
git clone https://gh-proxy.com/https://github.com/wangshuai09/vllm.git
git clone https://gh-proxy.com/https://gitee.com/ascend/MindSpeed.git
git clone https://gh-proxy.com/https://github.com/NVIDIA/Megatron-LM.git
git clone https://gh-proxy.com/https://github.com/huggingface/trl.git
git clone https://gh-proxy.com/https://github.com/hkust-nlp/simpleRL-reason.git
git clone https://gh-proxy.com/https://github.com/as12138/verl.git verl-npu
```



## Git 仓库合并外部PR

将 Git 仓库的 Pull Request (PR) 合并到主仓库的步骤如下，具体操作可能因代码托管平台（如 GitHub、GitLab、Bitbucket 等）略有不同，但核心流程一致。以下是通用步骤：

---

### **1. 确保你有合并权限**

- 你需要在主仓库有 **写入权限** 或 **合并 PR 的权限**（如果是开源项目，可能需要维护者审核）。

---

### **2. 在代码托管平台上操作（以 GitHub 为例）**
#### **方法一：通过 Web 界面合并**
1. **进入 PR 页面**
   在仓库的 `Pull Requests` 标签页找到目标 PR。

2. **检查 PR 状态**
   - 确保 CI 检查通过（如 GitHub Actions、Travis CI 等）。
   - 确保没有冲突（若有冲突需先解决）。

3. **选择合并方式**
   GitHub 提供三种合并选项（点击 `Merge pull request` 下拉菜单）：
   - **Create a merge commit**：生成一个合并提交（保留完整历史，推荐）。
   - **Squash and merge**：将多个提交压缩成一个（简化历史）。
   - **Rebase and merge**：线性合并（不推荐用于多人协作的主分支）。

4. **确认合并**
   点击 `Confirm merge`，PR 会被合并到目标分支（通常是 `main` 或 `master`）。

5. **删除分支（可选）**
   合并后可以点击 `Delete branch` 清理来源分支。

---

#### **方法二：通过命令行合并（适合需要本地检查的情况）**
1. **将主仓库和 PR 分支拉到本地**
   ```bash
   git clone <主仓库URL>
   cd <仓库目录>
   git remote add <贡献者名> <PR来源仓库URL>  # 如果PR来自外部仓库
   git fetch <贡献者名> <PR分支名>
   ```

2. **切换到目标分支并合并**
   ```bash
   git checkout main       # 切换到主分支
   git merge <PR分支名>    # 合并PR分支
   ```

3. **解决冲突（如果有）**
   - 手动解决冲突后提交：
     ```bash
     git add .
     git commit -m "Merge PR #<PR编号>: <描述>"
     ```

4. **推送到主仓库**
   ```bash
   git push origin main
   ```

---

### **3. 验证合并**
- 在仓库的 `Commits` 或 `Network` 图表中确认合并结果。
- 运行测试确保功能正常。

---

### **注意事项**
1. **权限问题**
   - 如果无权合并，需要联系仓库管理员。
2. **保护分支规则**
   - 主分支可能受保护（需通过 CI 或指定审核人）。
3. **代码审查**
   - 合并前建议通过 `Review` 功能进行代码审查。
4. **跨仓库 PR**
   - 如果 PR 来自外部仓库（Fork），需先拉取到本地检查。

---

### **其他平台差异**
- **GitLab**：操作类似，称为 `Merge Request (MR)`，合并按钮在 MR 页面。
- **Bitbucket**：流程相近，合并选项在 PR 页面的 `Merge` 按钮中。

通过以上步骤，你可以安全地将 PR 合并到主仓库。



## 模型-数据集下载

参考网站 https://hf-mirror.com/ 说明

### 安装依赖

```bash
pip install -U huggingface_hub
```

### 配置环境变量

在运行脚本前，需要配置以下环境变量以指定国内镜像源：
```bash
export HF_ENDPOINT="https://hf-mirror.com"
export HF_HUB_ENABLE_HF_TRANSFER=0
```
注意：如果无法访问 `https://hf-mirror.com`，请检查链接的合法性或网络连接。如果问题持续存在，可以尝试更换其他可用的镜像源。

### 下载模型权重

运行脚本后，将按以下路径下载指定的模型权重：
```bash
huggingface-cli download Qwen/Qwen2.5-0.5B --local-dir /root/llmtuner/hfhub/models/Qwen/Qwen2.5-0.5B
huggingface-cli download Qwen/Qwen2.5-0.5B-Instruct --local-dir /root/llmtuner/hfhub/models/Qwen/Qwen2.5-0.5B-Instruct
```

### 下载数据集

```bash
huggingface-cli download  --repo-type dataset openai/gsm8k  --local-dir /root/llmtuner/hfhub/datasets/openai/gsm8k
huggingface-cli download  --repo-type dataset BytedTsinghua-SIA/DAPO-Math-17k  --local-dir /root/llmtuner/hfhub/datasets/BytedTsinghua-SIA/DAPO-Math-17k
```

### Shell 脚本

以下是完整的脚本内容，您可以将其保存为 `download_script.sh` 并运行：
```bash
#!/bin/bash
# 需要配置国内镜像源
export HF_ENDPOINT="https://hf-mirror.com"
export HF_HUB_ENABLE_HF_TRANSFER=0

# 模型权重
## Qwen2.5
huggingface-cli download Qwen/Qwen2.5-0.5B --local-dir /root/llmtuner/hfhub/models/Qwen/Qwen2.5-0.5B
huggingface-cli download Qwen/Qwen2.5-0.5B-Instruct --local-dir /root/llmtuner/hfhub/models/Qwen/Qwen2.5-0.5B-Instruct

## 数据集
huggingface-cli download  --repo-type dataset openai/gsm8k  --local-dir /root/llmtuner/hfhub/datasets/openai/gsm8k
huggingface-cli download  --repo-type dataset BytedTsinghua-SIA/DAPO-Math-17k  --local-dir /root/llmtuner/hfhub/datasets/BytedTsinghua-SIA/DAPO-Math-17k
```



## 测试集群通信

创建文件名 allreduce_demo.py

```Python
import torch
import torch_npu
from torch_npu.contrib import transfer_to_npu
import torch.distributed as dist
import os

def main():
    # 初始化分布式环境
    local_rank = int(os.environ["LOCAL_RANK"])
    world_size = int(os.environ["WORLD_SIZE"])
    rank = int(os.environ["RANK"])

    # 设置NPU设备
    torch.npu.set_device(local_rank)
    # 获取当前设备
    device = torch.device(f"npu:{torch.npu.current_device()}")

    # 初始化进程组
    dist.init_process_group(backend="hccl")

    # 创建tensor并移到当前NPU设备
    tensor = torch.ones(2, 2, dtype=torch.float16, device=device) * (rank + 1)

    print(f'Rank {rank} 的初始tensor:\n{tensor}')
    print(f'Tensor dtype: {tensor.dtype}')
    print(f'Tensor device: {tensor.device}')

    # 执行all-reduce操作
    dist.all_reduce(tensor, op=dist.ReduceOp.SUM)

    print(f'Rank {rank} 的all-reduce结果:\n{tensor}')

    # 清理
    dist.destroy_process_group()

if __name__ == "__main__":
    main()
```

创建运行文件 run.sh

```Shell
#!/bin/bash

# 设置NPU可见设备
export ASCEND_VISIBLE_DEVICES=0,1,2,3,4,5,6,7

# 使用torchrun启动分布式训练
torchrun \
    --nproc_per_node=8 \
    --nnodes=1 \
    --node_rank=0 \
    --master_addr="localhost" \
    --master_port=29500 \
    allreduce_demo.py
```

执行 run.sh

```Shell
bash run.sh
```



##   常用集群任务命令

### 运行后台任务

使用 `nohup` 命令在后台运行脚本，并将输出重定向到日志文件：
```bash
nohup sh download_hf_weights.sh > output2.log 2>&1 &
```

### 查看后台进程

查看后台运行的进程：
```bash
ps aux | grep hugg
```

### Kill 命令

```Shell
ps aux | grep python | awk '{print $2}' | xargs kill -9
```

### 清理Torch 扩展缓存

清理 PyTorch 扩展的缓存文件：
```bash
rm -rf /root/.cache/torch_extensions/py310_cpu
```



## Wandb 同步本地 wandb 日志

如果你想将本地的 log 文件同步上传到 Weights & Biases (W&B)，可以使用 `wandb sync` 命令。以下是详细的方法：

------

### 1：自动同步

如果你是使用 `wandb.init()` 进行实验跟踪，并且在线运行，W&B 会 自动上传 训练日志，不需要额外操作。

### 2：手动同步本地日志

如果你在 离线模式 (`WANDB_MODE=offline`) 运行了实验，W&B 会将日志保存在本地。你可以手动上传这些日志。

#### 步骤 1：找到本地日志

W&B 默认将本地的日志存储在：

```bash
~/.wandb/
```

或者当前项目目录的 `wandb` 文件夹下：

```bash
wandb/run-<RUN_ID>/  # 每个实验的日志都在单独的文件夹
```

#### 步骤 2：手动同步

使用以下命令同步本地存储的日志：

```bash
wandb sync wandb/
```

或同步特定日志：

```bash
wandb sync wandb/run-<RUN_ID>/
```

#### 示例

如果你想同步所有未上传的日志：

```bash
wandb sync --sync-all
```

------

### 3：强制同步

如果 `wandb sync` 没有效果，可以尝试：

```bash
wandb sync --include-offline
```

或者清理无效的本地缓存后再同步：

```bash
wandb sync --clean
wandb sync
```

------

### 4：上传到特定项目

如果你想把日志上传到指定的 W&B 项目，可以在运行时设置：

```bash
WANDB_PROJECT="your_project_name" wandb sync wandb/
```

------

### 解决常见问题

### 1️⃣ `wandb sync` 没有效果？

可能原因：

- W&B 服务器无法访问（检查网络）
- 本地日志文件损坏
- 已经同步过了（可以用 `wandb sync --clean` 先清理）

## Wandb 同步本地 tensorbaord 日志

如果你有 本地 TensorBoard 日志（如 `.tfevents` 文件）并希望同步到 Weights & Biases (W&B)，可以按照以下步骤操作：

------

### 1：使用 `wandb sync` 命令

W&B 提供了 wandb sync 命令，可以直接同步本地 TensorBoard 文件：

```bash
wandb sync --sync-tensorboard <tensorboard_log_dir>
```

- `<tensorboard_log_dir>` 是你的 TensorBoard 日志目录，例如 `logs/`。这会自动解析 TensorBoard 的 `.tfevents` 文件，并将数据上传到 W&B。

### 2：使用 Python 代码直接同步

如果你在 Python 代码中运行 TensorBoard，可以手动集成 W&B：

#### 步骤 1：初始化 W&B

在你的训练脚本中：

```python
import wandb
wandb.init(project="your_project_name")
```

#### 步骤 2：让 W&B 监测 TensorBoard 日志

你可以让 W&B 监听 TensorBoard 目录：

```python
wandb.tensorboard.patch(root_logdir="logs/")
```

或者直接：

```python
wandb.init(sync_tensorboard=True)
```

#### 示例

```python
import wandb
import tensorflow as tf

# 初始化 wandb
wandb.init(project="my_project", sync_tensorboard=True)

# 定义 TensorBoard 目录
tensorboard_logdir = "logs/"

# 创建 TensorBoard 记录器
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tensorboard_logdir)

# 训练模型
model.fit(x_train, y_train, epochs=10, callbacks=[tensorboard_callback])
```

这样，TensorBoard 生成的 `.tfevents` 日志会 自动同步 到 W&B。

|#                            | 适用场景                          | 命令                                           |
| ------------------------------- | --------------------------------- | ---------------------------------------------- |
| `wandb sync --tensorboard`  | 现有 TensorBoard 日志 (.tfevents) | `wandb sync --tensorboard logs/`               |
| `wandb.tensorboard.patch()` | 在训练过程中同步                  | `wandb.tensorboard.patch(root_logdir="logs/")` |
